{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "* This project aims to create a schema that can derive various correlations using three datasets, demographics of US states and cities dataset, global temperature data of countries dataset and i94 immigration dataset. For example, is there any correlation beetween the average temperature of residence country and going to united state.\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "import configparser\n",
    "from datetime import datetime\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear, date_format, dayofweek\n",
    "from pyspark.sql import functions as F\n",
    "import datetime as dt\n",
    "from pyspark.sql.functions import isnan, when, count, col, udf, dayofmonth, dayofweek, month, year, weekofyear, avg, monotonically_increasing_id\n",
    "from pyspark.sql.types import *\n",
    "import requests\n",
    "from pyspark.sql.functions import year, month, dayofmonth, weekofyear, date_format\n",
    "from pyspark.sql import SparkSession, SQLContext, GroupedData, HiveContext\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import date_add as d_add\n",
    "from pyspark.sql.types import DoubleType, StringType, IntegerType, FloatType, DateType\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql import Row\n",
    "import re\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import initcap, udf, lit, explode, split, regexp_extract, col, isnan, isnull, desc, when, sum, to_date, desc, regexp_replace, count, to_timestamp\n",
    "from pyspark.sql.types import IntegerType,BooleanType,DateType\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "* The steps to create the analytics model database: \n",
    "- Use pandas and Spark python dataframe to load the data\n",
    "- Explore I94 immigration dataset to identify missing values and perform data cleaning\n",
    "- Explore demographics dataset to identify missing values and perform data cleaning\n",
    "- Explore temperatures dataset by country to identify missing values and perform data cleaning\n",
    "- Extract Port, Country , State, Visa and Mode of travel from sas_label file and perform join with I94 dataset\n",
    "- Create star schema\n",
    "    - Dimension tables :\n",
    "        1. Extract and create ArrivalDate dimension from i94 dataset, this dimension can join the fact table through the arrdate feature. \n",
    "        2. Extract and create I94Port dimension from i94 sas_label file, this dimension can join the fact table through the i94port feature.\n",
    "        3. Create demographics_df dimension from the us_cities_demographics dataset. This dimension can join the fact table through the stateCode feature.\n",
    "        4. Create GlobalLandTemperaturesByCity dimension from the GlobalLandTemperaturesByCity dataset. This dimension can join the fact table through the Country feature.\n",
    "        \n",
    "    - Create the fact table from the cleaned I94 dataset.\n",
    "\n",
    "-  Apache Spark is the technology that used in this project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets \n",
    "- I94 Immigration Data: This data comes from the US National Tourism and Trade Office. A data dictionary is included in the workspace. [This](https://www.trade.gov/national-travel-and-tourism-office) is where the data comes from. There's a sample file so you can take a look at the data in csv format before reading it all in. You do not have to use the entire dataset, just use what you need to accomplish the goal you set at the beginning of the project.\n",
    "- World Temperature Data: This dataset came from Kaggle. You can read more about it [here](https://www.kaggle.com/datasets/berkeleyearth/climate-change-earth-surface-temperature-data).\n",
    "- U.S. City Demographic Data: This data comes from OpenSoft. You can read more about it [here](https://public.opendatasoft.com/explore/dataset/us-cities-demographics/export/).\n",
    "- Airport Code Table: This is a simple table of airport codes and corresponding cities. It comes from [here](https://datahub.io/core/airport-codes#data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = '../../data2/GlobalLandTemperaturesByCity.csv'\n",
    "df = pd.read_csv(fname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.737</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt  AverageTemperature  AverageTemperatureUncertainty   City  \\\n",
       "0  1743-11-01               6.068                          1.737  Århus   \n",
       "1  1743-12-01                 NaN                            NaN  Århus   \n",
       "2  1744-01-01                 NaN                            NaN  Århus   \n",
       "3  1744-02-01                 NaN                            NaN  Århus   \n",
       "4  1744-03-01                 NaN                            NaN  Århus   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- dt : Date time\n",
    "- AverageTemperature : Average temperature in celsius\n",
    "- AverageTemperatureUncertainty : 95% confidence interval around average temperature\n",
    "- City : Name of city\n",
    "- Country : Name of country\n",
    "- Latitude : Latitude of city\n",
    "- Longitude : Longitude of city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8599212, 7)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\").\\\n",
    "config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n",
    "enableHiveSupport().getOrCreate()\n",
    "\n",
    "df_spark = spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>U</td>\n",
       "      <td>None</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>10282016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.897628e+09</td>\n",
       "      <td>None</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate i94mode i94addr  \\\n",
       "0    6.0  2016.0     4.0   692.0   692.0     XXX  20573.0    None    None   \n",
       "\n",
       "  depdate   ...     entdepu  matflag  biryear   dtaddto gender insnum airline  \\\n",
       "0    None   ...           U     None   1979.0  10282016   None   None    None   \n",
       "\n",
       "         admnum fltno visatype  \n",
       "0  1.897628e+09  None       B2  \n",
       "\n",
       "[1 rows x 28 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark_pandas=df_spark.limit(1)\n",
    "df_spark_pandas.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cicid : Unique ID\n",
    "- type : Airport type\n",
    "- i94mon : month\n",
    "- i94cit : 3 digit code for immigrant country of birth\n",
    "- i94res : 3 digit code for immigrant country of residence\n",
    "- i94port : Port of admission\n",
    "- arrdate : Arrival Date in the USA\n",
    "- i94mode : Mode of transportation (1 = Air; 2 = Sea; 3 = Land; 9 = Not reported)\n",
    "- i94addr : USA State of arrival\n",
    "- depdate : Departure Date from the USA\n",
    "- i94bir : Age of Respondent in Years\n",
    "- i94visa : Visa codes collapsed into three categories\n",
    "- count : Field used for summary statistics\n",
    "- dtadfile : Character Date Field - Date added to I-94 Files\n",
    "- visapost : Department of State where Visa was issued\n",
    "- occup : Occupation that will be performed in U.S\n",
    "- entdepa : Arrival Flag - admitted or paroled into the U.S.\n",
    "- entdepd : Departure Flag - Departed, lost I-94 or is deceased\n",
    "- entdepu : Update Flag - Either apprehended, overstayed, adjusted to perm residence\n",
    "- matflag : Match flag - Match of arrival and departure records\n",
    "- biryear : 4 digit year of birth\n",
    "- dtaddto : Character Date Field - Date to which admitted to U.S. (allowed to stay until)\n",
    "- gender : Non-immigrant sex\n",
    "- insnum : INS number\n",
    "- airline : Airline used to arrive in U.S\n",
    "- admnum : Admission Number\n",
    "- fltno : Flight number of Airline used to arrive in U.S.\n",
    "- visatype : Class of admission legally admitting the non-immigrant to temporarily stay in U.S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3096313"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write to parquet\n",
    "#df_spark.write.parquet(\"sas_data\")\n",
    "#df_spark=spark.read.parquet(\"sas_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "airport_codes = 'airport-codes_csv.csv'\n",
    "airport_df = pd.read_csv(airport_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55075, 12)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident      type               name  elevation_ft continent iso_country  \\\n",
       "0   00A  heliport  Total Rf Heliport          11.0       NaN          US   \n",
       "\n",
       "  iso_region municipality gps_code iata_code local_code  \\\n",
       "0      US-PA     Bensalem      00A       NaN        00A   \n",
       "\n",
       "                          coordinates  \n",
       "0  -74.93360137939453, 40.07080078125  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ident : Unique identifier\n",
    "- type : Airport type\n",
    "- name : Airport name\n",
    "- elevation_ft : Airport altitude\n",
    "- continent : Continent name\n",
    "- iso_country : The International Organization for Standardization code for the airport's country\n",
    "- iso_region : The International Organization for Standardization code for the airport's region\n",
    "- municipality : municipality where the airport is located\n",
    "- gps_code : Airport GPS Code\n",
    "- iata_code : Airport International Air Transport Association's Code\n",
    "- local_code : Airport local code\n",
    "- coordinates : Airport coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_cities_demographics = 'us-cities-demographics.csv'\n",
    "demographics_df = pd.read_csv(us_cities_demographics, header=0, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2891, 12)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographics_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            City     State  Median Age  Male Population  Female Population  \\\n",
       "0  Silver Spring  Maryland        33.8          40601.0            41862.0   \n",
       "\n",
       "   Total Population  Number of Veterans  Foreign-born  Average Household Size  \\\n",
       "0             82463              1562.0       30908.0                     2.6   \n",
       "\n",
       "  State Code                Race  Count  \n",
       "0         MD  Hispanic or Latino  25924  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographics_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- City : City Name\n",
    "- State : US State of the City\n",
    "- Median Age : The median population age\n",
    "- Male Population : Male population total\n",
    "- Female Population : Female population total\n",
    "- Total Population : Total population\n",
    "- Number of Veterans : Number of veterans living in the city\n",
    "- Foreign-born : Number of residents who were not born in the city\n",
    "- Average Household Size : Average size of houses in the city\n",
    "- State Code : Code of the state\n",
    "- Race : Race class\n",
    "- Count : Number of individuals in each race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "\n",
    "#spark = SparkSession.builder.\\\n",
    "#config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\").\\\n",
    "#config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n",
    "#enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark=spark.read.parquet(\"sas_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3096313"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|    cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|        admnum|fltno|visatype|\n",
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|5748517.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     CA|20582.0|  40.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1976.0|10292016|     F|  null|     QF|9.495387003E10|00011|      B1|\n",
      "|5748518.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     NV|20591.0|  32.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1984.0|10292016|     F|  null|     VA|9.495562283E10|00007|      B1|\n",
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+\n",
      "|i94mon|count  |\n",
      "+------+-------+\n",
      "|4.0   |3096313|\n",
      "+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum,avg,max,count\n",
    "df_spark.groupBy(\"i94mon\").agg(count(\"*\").alias(\"count\")).show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cicid': 0.0,\n",
       " 'i94yr': 0.0,\n",
       " 'i94mon': 0.0,\n",
       " 'i94cit': 0.0,\n",
       " 'i94res': 0.0,\n",
       " 'i94port': 0.0,\n",
       " 'arrdate': 0.0,\n",
       " 'i94mode': 0.007718857880324115,\n",
       " 'i94addr': 4.928183940060324,\n",
       " 'depdate': 4.6008591508675,\n",
       " 'i94bir': 0.025901774142342845,\n",
       " 'i94visa': 0.0,\n",
       " 'count': 0.0,\n",
       " 'dtadfile': 3.229647648671178e-05,\n",
       " 'visapost': 60.75774639062653,\n",
       " 'occup': 99.73755883206898,\n",
       " 'entdepa': 0.0076865614038374025,\n",
       " 'entdepd': 4.470768943579024,\n",
       " 'entdepu': 99.98733978121722,\n",
       " 'matflag': 4.470768943579024,\n",
       " 'biryear': 0.025901774142342845,\n",
       " 'dtaddto': 0.015405419284161517,\n",
       " 'gender': 13.379429017673601,\n",
       " 'insnum': 96.32763225164898,\n",
       " 'airline': 2.700857439154246,\n",
       " 'admnum': 0.0,\n",
       " 'fltno': 0.6313638188387285,\n",
       " 'visatype': 0.0}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_percentage_df = df_spark.select([(count(when(isnan(c) | col(c).isNull(), c))*100/count(lit(1))).alias(c) for c in df_spark.columns])\n",
    "missing_percentage_df = missing_percentage_df.collect()[0].asDict()\n",
    "missing_percentage_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['occup', 'entdepu', 'insnum']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_columns = [k for k, v in missing_percentage_df.items() if v > 80]\n",
    "drop_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "i94_df = df_spark.drop(*drop_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i94_df.groupBy(\"cicid\").count().where(\"count > 1\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_dt(i):\n",
    "    try:\n",
    "        s = datetime(1960,1,1)\n",
    "        d = timedelta(days=int(i))\n",
    "        return s + d\n",
    "    except:\n",
    "        ex = datetime(1960,1,1)\n",
    "        return ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "depdate_datetime_udf = udf(lambda i: convert_to_dt(i), DateType())\n",
    "i94_df = i94_df.withColumn('depdate', to_date(depdate_datetime_udf(col('depdate'))))\n",
    "i94_df = i94_df.withColumn('depdate', to_date(depdate_datetime_udf(col('depdate'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+------+------+------+-------+-------+-------+-------+----------+------+-------+-----+--------+--------+-------+-------+-------+-------+--------+------+-------+--------------+-----+--------+\n",
      "|    cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|   depdate|i94bir|i94visa|count|dtadfile|visapost|entdepa|entdepd|matflag|biryear| dtaddto|gender|airline|        admnum|fltno|visatype|\n",
      "+---------+------+------+------+------+-------+-------+-------+-------+----------+------+-------+-----+--------+--------+-------+-------+-------+-------+--------+------+-------+--------------+-----+--------+\n",
      "|5748517.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     CA|1960-01-01|  40.0|    1.0|  1.0|20160430|     SYD|      G|      O|      M| 1976.0|10292016|     F|     QF|9.495387003E10|00011|      B1|\n",
      "|5748518.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     NV|1960-01-01|  32.0|    1.0|  1.0|20160430|     SYD|      G|      O|      M| 1984.0|10292016|     F|     VA|9.495562283E10|00007|      B1|\n",
      "+---------+------+------+------+------+-------+-------+-------+-------+----------+------+-------+-----+--------+--------+-------+-------+-------+-------+--------+------+-------+--------------+-----+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "TextFile = 'I94_SAS_Labels_Descriptions.SAS'\n",
    "\n",
    "df_label = spark.read.text(TextFile, wholetext=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf\n",
    "def matching(TextFile, TextPattern): \n",
    "    return re.search(TextPattern, TextFile).group(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_I94CitRes_1 = df_label.withColumn('I94CitRes_1', matching(\"value\", lit(\"(\\/\\* I94CIT & I94RES[^;]+)\"))).select(\"I94CitRes_1\")\n",
    "df_I94CitRes_2 = df_I94CitRes_1.withColumn('I94CitRes_2', explode(split(\"I94CitRes_1\", \"[\\r\\n]+\"))).select('I94CitRes_2')\n",
    "df_I94CitRes_3 = df_I94CitRes_2.filter(df_I94CitRes_2['I94CitRes_2'].rlike(\"([0-9]+ *\\= *[0-9A-Za-z \\:\\',\\-()\\/\\.#&]+)\"))\\\n",
    ".withColumn('country_code', regexp_extract(df_I94CitRes_2['I94CitRes_2'], \"[0-9]+\", 0))\\\n",
    ".withColumn('country_code',col('country_code').cast(IntegerType()))\\\n",
    ".withColumn('country_name', regexp_extract(df_I94CitRes_2['I94CitRes_2'], \"(?<=')([0-9A-Za-z \\:\\',\\-()\\/\\.#&]+)(?=')\", 0))\\\n",
    ".withColumn('country_name',initcap(col('country_name')))\\\n",
    ".withColumn('country_name',when(col('country_name') == 'Mexico Air Sea, And Not Reported (i-94, No Land Arrivals)','Mexico')\\\n",
    "            .otherwise(col('country_name')))\\\n",
    ".drop(\"I94CitRes_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mexico'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_I94CitRes_3.select(col(\"country_name\")).collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+\n",
      "|country_code|country_name|\n",
      "+------------+------------+\n",
      "|582         |Mexico      |\n",
      "+------------+------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_I94CitRes_3.show(1,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|country_code|count|\n",
      "+------------+-----+\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col,isnan, when, count\n",
    "\n",
    "df_I94CitRes_3.groupBy(\"country_code\").count().where(\"count > 1\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+\n",
      "|country_code|country_name|\n",
      "+------------+------------+\n",
      "|           0|           0|\n",
      "+------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_I94CitRes_3.select([count(when(isnan(a) | col(a).isNull(), a)).alias(a) for a in df_I94CitRes_3.columns]\n",
    "   ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_I94Port1 = df_label.withColumn('I94Port1', matching(\"value\", lit(\"(\\/\\* I94PORT[^;]+)\"))).select(\"I94Port1\")\n",
    "\n",
    "df_I94Port2 = df_I94Port1.withColumn('I94Port_2', explode(split(\"I94Port1\", \"[\\r\\n]+\"))).select('I94Port_2')\n",
    "\n",
    "df_I94Port3 = df_I94Port2.filter(df_I94Port2['I94Port_2'].rlike(\"([0-9A-Z.' ]+\\t*\\=\\t*[0-9A-Za-z \\',\\-()\\/\\.#&]*)\"))\\\n",
    ".withColumn('portCode', regexp_extract(df_I94Port2['I94Port_2'], \"(?<=')[0-9A-Z. ]+(?=')\", 0))\\\n",
    ".withColumn('cityName_stateCode', regexp_extract(col('I94Port_2'), \"(?<=\\t')([0-9A-Za-z ,\\-()\\/\\.#&]+)(?=')\", 0))\\\n",
    ".withColumn('cityName', split(col('cityName_stateCode'), ',').getItem(0))\\\n",
    ".withColumn('stateCode', split(col('cityName_stateCode'), ',').getItem(1))\\\n",
    ".withColumn('stateCode', regexp_replace(col('stateCode'), '\\s*', ''))\\\n",
    ".withColumn('cityName',initcap(col('cityName')))\\\n",
    ".withColumn('stateCode', when(col('stateCode') == 'CA(BPS)','CA')\\\n",
    "            .when(col('stateCode') == 'AR(BPS)','AR')\\\n",
    "            .when(col('stateCode') == 'HWY.STATION','CA')\\\n",
    "            .when(col('stateCode') == 'CO#ARPT','CO')\\\n",
    "            .when(col('stateCode') == 'FL#ARPT','FL')\\\n",
    "            .when(col(\"stateCode\").isNull(), \"AZ\")\\\n",
    "            .otherwise(col('stateCode')))\\\n",
    ".drop('I94Port_2')\n",
    "df_I94Port3=df_I94Port3.withColumn('stateCode',when((df_I94Port3.portCode == \"WAS\")&(df_I94Port3.stateCode == 'AZ') , \"DC\")\\\n",
    "                                   .otherwise(col('stateCode')))\n",
    "df_I94Port3=df_I94Port3.withColumn('cityName', when(df_I94Port3.portCode == 'MAP','Mariposa')\\\n",
    "                                   .otherwise(col('cityName')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------------------+------------------------+---------+\n",
      "|portCode|cityName_stateCode          |cityName                |stateCode|\n",
      "+--------+----------------------------+------------------------+---------+\n",
      "|ALC     |ALCAN, AK                   |Alcan                   |AK       |\n",
      "|ANC     |ANCHORAGE, AK               |Anchorage               |AK       |\n",
      "|BAR     |BAKER AAF - BAKER ISLAND, AK|Baker Aaf - Baker Island|AK       |\n",
      "|DAC     |DALTONS CACHE, AK           |Daltons Cache           |AK       |\n",
      "|PIZ     |DEW STATION PT LAY DEW, AK  |Dew Station Pt Lay Dew  |AK       |\n",
      "|DTH     |DUTCH HARBOR, AK            |Dutch Harbor            |AK       |\n",
      "|EGL     |EAGLE, AK                   |Eagle                   |AK       |\n",
      "|FRB     |FAIRBANKS, AK               |Fairbanks               |AK       |\n",
      "|HOM     |HOMER, AK                   |Homer                   |AK       |\n",
      "|HYD     |HYDER, AK                   |Hyder                   |AK       |\n",
      "+--------+----------------------------+------------------------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_I94Port3.show(10,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- portCode: string (nullable = true)\n",
      " |-- cityName_stateCode: string (nullable = true)\n",
      " |-- cityName: string (nullable = true)\n",
      " |-- stateCode: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_I94Port3.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------------+---------+---------+\n",
      "|portCode|cityName_stateCode    |cityName |stateCode|\n",
      "+--------+----------------------+---------+---------+\n",
      "|ANC     |ANCHORAGE, AK         |Anchorage|AK       |\n",
      "+--------+----------------------+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_I94Port3.filter(df_I94Port3.cityName == \"Anchorage\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|portCode|count|\n",
      "+--------+-----+\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_I94Port3.groupBy(\"portCode\").count().where(\"count > 1\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+--------+---------+\n",
      "|portCode|cityName_stateCode|cityName|stateCode|\n",
      "+--------+------------------+--------+---------+\n",
      "|       0|                 0|       0|        0|\n",
      "+--------+------------------+--------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col,isnan, when, count\n",
    "df_I94Port3.select([count(when(isnan(a) | col(a).isNull(), a)).alias(a) for a in df_I94Port3.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_I94Addr_1 = df_label.withColumn('I94Addr_1', matching(\"value\", lit(\"(\\/\\* I94ADDR[^;]+)\"))).select(\"I94Addr_1\")\n",
    "\n",
    "df_I94Addr_2 = df_I94Addr_1.withColumn('I94Addr_2', explode(split(\"I94Addr_1\", \"[\\r\\n]+\"))).select('I94Addr_2')\n",
    "\n",
    "df_I94Addr_3 = df_I94Addr_2.filter(df_I94Addr_2['I94Addr_2'].rlike(\"(\\t*[0-9A-Z.' ]+\\=\\t*[0-9A-Za-z \\',\\-()\\/\\.#&]*)\"))\\\n",
    ".withColumn('stateCode', regexp_extract(df_I94Addr_2['I94Addr_2'], \"(?<=\\t')[0-9A-Z. ]+(?=')\", 0))\\\n",
    ".withColumn('stateName', regexp_extract(df_I94Addr_2['I94Addr_2'], \"(?<=\\=')([0-9A-Za-z ,\\-()\\/\\.#&]+)(?=')\", 0))\\\n",
    ".withColumn('stateName',initcap(col('stateName')))\\\n",
    ".drop(\"I94Addr_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+\n",
      "|stateCode|stateName|\n",
      "+---------+---------+\n",
      "|AL       |Alabama  |\n",
      "+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_I94Addr_3.filter(df_I94Addr_3.stateName == \"Alabama\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_I94Mode_1 = df_label.withColumn('I94Mode_1', matching(\"value\", lit(\"(\\/\\* I94MODE[^;]+)\"))).select(\"I94Mode_1\")\n",
    "\n",
    "df_I94Mode_2 = df_I94Mode_1.withColumn('I94Mode_2', explode(split(\"I94Mode_1\", \"[\\r\\n]+\"))).select('I94Mode_2')\n",
    "\n",
    "df_I94Mode_3 = df_I94Mode_2.filter(df_I94Mode_2['I94Mode_2']\\\n",
    "                                                                    .rlike(\"(\\t*[0-9]+ *\\= *[0-9A-Za-z \\',\\-()\\/\\.#&]*)\"))\\\n",
    ".withColumn('travelModeCode', regexp_extract(df_I94Mode_2['I94Mode_2'], \"(?<=\\t)[0-9]+(?= )\", 0))\\\n",
    ".withColumn('travelModeName', regexp_extract(df_I94Mode_2['I94Mode_2'], \"(?<=\\= ')([A-Za-z ,\\-()\\/\\.#&]+)(?=')\", 0))\\\n",
    ".drop(\"I94Mode_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+\n",
      "|travelModeCode|travelModeName|\n",
      "+--------------+--------------+\n",
      "|             1|           Air|\n",
      "|             2|           Sea|\n",
      "|             3|          Land|\n",
      "|             9|  Not reported|\n",
      "+--------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_I94Mode_3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_I94Visa_1 = df_label.withColumn('I94Visa_1', matching(\"value\", lit(\"(\\/\\* I94VISA[^;]+)\"))).select(\"I94Visa_1\")\n",
    "\n",
    "df_I94Visa_2 = df_I94Visa_1.withColumn('I94Visa_2', explode(split(\"I94Visa_1\", \"[\\r\\n]+\"))).select('I94Visa_2')\n",
    "\n",
    "df_I94Visa_3 = df_I94Visa_2.filter(df_I94Visa_2['I94Visa_2'].rlike(\"(\\s*[0-9]+ *\\= *[A-Za-z]*)\"))\\\n",
    ".withColumn('VisaCategoryCode', regexp_extract(df_I94Visa_2['I94Visa_2'], \"[0-9]+\", 0))\\\n",
    ".withColumn('VisaCategoryName', regexp_extract(df_I94Visa_2['I94Visa_2'], \"[A-Za-z]+\", 0))\\\n",
    ".drop(\"I94Visa_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------+\n",
      "|VisaCategoryCode|VisaCategoryName|\n",
      "+----------------+----------------+\n",
      "|               1|        Business|\n",
      "|               2|        Pleasure|\n",
      "|               3|         Student|\n",
      "+----------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_I94Visa_3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "airport_codes = 'airport-codes_csv.csv'\n",
    "airport_df = pd.read_csv(airport_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55075, 12)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>820.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>00AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.77030181884766, 34.86479949951172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AR</td>\n",
       "      <td>closed</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>237.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AR</td>\n",
       "      <td>Newport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-91.254898, 35.6087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                                name  elevation_ft  \\\n",
       "0   00A       heliport                   Total Rf Heliport          11.0   \n",
       "1  00AA  small_airport                Aero B Ranch Airport        3435.0   \n",
       "2  00AK  small_airport                        Lowell Field         450.0   \n",
       "3  00AL  small_airport                        Epps Airpark         820.0   \n",
       "4  00AR         closed  Newport Hospital & Clinic Heliport         237.0   \n",
       "\n",
       "  continent iso_country iso_region  municipality gps_code iata_code  \\\n",
       "0       NaN          US      US-PA      Bensalem      00A       NaN   \n",
       "1       NaN          US      US-KS         Leoti     00AA       NaN   \n",
       "2       NaN          US      US-AK  Anchor Point     00AK       NaN   \n",
       "3       NaN          US      US-AL       Harvest     00AL       NaN   \n",
       "4       NaN          US      US-AR       Newport      NaN       NaN   \n",
       "\n",
       "  local_code                            coordinates  \n",
       "0        00A     -74.93360137939453, 40.07080078125  \n",
       "1       00AA                 -101.473911, 38.704022  \n",
       "2       00AK            -151.695999146, 59.94919968  \n",
       "3       00AL  -86.77030181884766, 34.86479949951172  \n",
       "4        NaN                    -91.254898, 35.6087  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate = airport_df[airport_df.duplicated([\"iso_region\",\"municipality\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>00TE</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Tcjc-Northeast Campus Heliport</td>\n",
       "      <td>600.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-TX</td>\n",
       "      <td>Fort Worth</td>\n",
       "      <td>00TE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00TE</td>\n",
       "      <td>-97.18949890136719, 32.847599029541016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>01TS</td>\n",
       "      <td>closed</td>\n",
       "      <td>St Joseph Hospital Heliport</td>\n",
       "      <td>675.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-TX</td>\n",
       "      <td>Fort Worth</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-97.324501, 32.7285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>02TE</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Baylor Medical Center Heliport</td>\n",
       "      <td>560.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-TX</td>\n",
       "      <td>Waxahachie</td>\n",
       "      <td>02TE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02TE</td>\n",
       "      <td>-96.86419677734375, 32.39540100097656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>02TS</td>\n",
       "      <td>closed</td>\n",
       "      <td>FWOMC Heliport</td>\n",
       "      <td>684.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-TX</td>\n",
       "      <td>Fort Worth</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-97.370003, 32.747601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>03MT</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Cascade Field</td>\n",
       "      <td>3580.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-MT</td>\n",
       "      <td>Cascade</td>\n",
       "      <td>3MT7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3MT7</td>\n",
       "      <td>-111.71748, 47.267327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>03OH</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Gibbs Field</td>\n",
       "      <td>580.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-OH</td>\n",
       "      <td>Fremont</td>\n",
       "      <td>03OH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>03OH</td>\n",
       "      <td>-83.01740264892578, 41.418399810791016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>03PS</td>\n",
       "      <td>closed</td>\n",
       "      <td>Ziggy's Field</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bellefonte</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-77.905602, 40.849998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>05AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Wasilla Creek Airpark</td>\n",
       "      <td>620.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Palmer</td>\n",
       "      <td>05AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>05AK</td>\n",
       "      <td>-149.1880035, 61.66830063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>05II</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Reichhart Airport</td>\n",
       "      <td>795.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-IN</td>\n",
       "      <td>New Haven</td>\n",
       "      <td>05II</td>\n",
       "      <td>NaN</td>\n",
       "      <td>05II</td>\n",
       "      <td>-84.99720001220703, 41.02870178222656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>05PA</td>\n",
       "      <td>heliport</td>\n",
       "      <td>PECO Mob. Heliport</td>\n",
       "      <td>110.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>05PA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>05PA</td>\n",
       "      <td>-75.178201, 39.9548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>05WA</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Sacred Heart Medical Center Helistop</td>\n",
       "      <td>2220.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-WA</td>\n",
       "      <td>Spokane</td>\n",
       "      <td>05WA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>05WA</td>\n",
       "      <td>-117.41400146484375, 47.64820098876953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>06NH</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Cole Farm Airport</td>\n",
       "      <td>160.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-NH</td>\n",
       "      <td>Kensington</td>\n",
       "      <td>06NH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>06NH</td>\n",
       "      <td>-70.97309875488281, 42.92839813232422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>06NV</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Silver Creek Airport</td>\n",
       "      <td>5556.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-NV</td>\n",
       "      <td>Baker</td>\n",
       "      <td>06NV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>06NV</td>\n",
       "      <td>-114.150277, 39.098333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>06OR</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Hayden Mountain Airport</td>\n",
       "      <td>850.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-OR</td>\n",
       "      <td>Forest Grove</td>\n",
       "      <td>06OR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>06OR</td>\n",
       "      <td>-123.08000183105469, 45.4650993347168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>06PN</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Schiavoni Heliport</td>\n",
       "      <td>727.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Harrisburg</td>\n",
       "      <td>06PN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>06PN</td>\n",
       "      <td>-76.772533, 40.382733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>06WA</td>\n",
       "      <td>heliport</td>\n",
       "      <td>N A Degerstrom Yard Heliport</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-WA</td>\n",
       "      <td>Spokane</td>\n",
       "      <td>06WA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>06WA</td>\n",
       "      <td>-117.197998046875, 47.68629837036133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>07AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Pan Lake Strip Airport</td>\n",
       "      <td>357.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Willow</td>\n",
       "      <td>07AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>07AA</td>\n",
       "      <td>-149.9549028, 61.6959639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>07NV</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Border Line Farm Airport</td>\n",
       "      <td>5120.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-NV</td>\n",
       "      <td>Baker</td>\n",
       "      <td>07NV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>07NV</td>\n",
       "      <td>-114.053472, 39.102239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>07TS</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Cross-Country Estates Airport</td>\n",
       "      <td>690.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-TX</td>\n",
       "      <td>Georgetown</td>\n",
       "      <td>07TS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>07TS</td>\n",
       "      <td>-97.57279968261719, 30.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>07WA</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Multicare Deaconess Hospital Heliport</td>\n",
       "      <td>2110.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-WA</td>\n",
       "      <td>Spokane</td>\n",
       "      <td>07WA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>07WA</td>\n",
       "      <td>-117.424477, 47.651637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>08FA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Duda Airstrip</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-FL</td>\n",
       "      <td>La Belle</td>\n",
       "      <td>08FA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08FA</td>\n",
       "      <td>-81.48370361328125, 26.57979965209961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>08FD</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Sunniland Ranch Airport</td>\n",
       "      <td>65.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-FL</td>\n",
       "      <td>Okeechobee</td>\n",
       "      <td>08FD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08FD</td>\n",
       "      <td>-80.77279663085938, 27.363100051879883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>08FL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>J. H. Hendrie Farms Airport</td>\n",
       "      <td>103.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-FL</td>\n",
       "      <td>Lake Placid</td>\n",
       "      <td>08FL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08FL</td>\n",
       "      <td>-81.32869720458984, 27.08449935913086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>08LA</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Air Oil Inc Nr 2 Heliport</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-LA</td>\n",
       "      <td>Harahan</td>\n",
       "      <td>08LA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08LA</td>\n",
       "      <td>-90.18260192871094, 29.952999114990234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>08NY</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Md1 Airport</td>\n",
       "      <td>650.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-NY</td>\n",
       "      <td>Middletown</td>\n",
       "      <td>08NY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08NY</td>\n",
       "      <td>-74.50559997558594, 41.368099212646484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>08OR</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Saxon Sycan Airport</td>\n",
       "      <td>4990.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-OR</td>\n",
       "      <td>Silver Lake</td>\n",
       "      <td>08OR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08OR</td>\n",
       "      <td>-121.11699676513672, 42.839298248291016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>09AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>West Beaver Airport</td>\n",
       "      <td>228.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Big Lake</td>\n",
       "      <td>09AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>09AK</td>\n",
       "      <td>-149.847333, 61.589361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>09CN</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Tulare Motor Sports #2 Heliport</td>\n",
       "      <td>272.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-CA</td>\n",
       "      <td>Tulare</td>\n",
       "      <td>09CN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>09CN</td>\n",
       "      <td>-119.313572, 36.182556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>09FA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Placid Lakes Airport</td>\n",
       "      <td>130.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-FL</td>\n",
       "      <td>Lake Placid</td>\n",
       "      <td>09FA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>09FA</td>\n",
       "      <td>-81.41310119628906, 27.2455997467041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>09FD</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Cheryl-Lane Landings Airport</td>\n",
       "      <td>71.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-FL</td>\n",
       "      <td>Bushnell</td>\n",
       "      <td>09FD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>09FD</td>\n",
       "      <td>-82.0873031616211, 28.671100616455078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54929</th>\n",
       "      <td>ZSPD</td>\n",
       "      <td>large_airport</td>\n",
       "      <td>Shanghai Pudong International Airport</td>\n",
       "      <td>13.0</td>\n",
       "      <td>AS</td>\n",
       "      <td>CN</td>\n",
       "      <td>CN-31</td>\n",
       "      <td>Shanghai</td>\n",
       "      <td>ZSPD</td>\n",
       "      <td>PVG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>121.80500030517578, 31.143400192260742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54934</th>\n",
       "      <td>ZSSS</td>\n",
       "      <td>large_airport</td>\n",
       "      <td>Shanghai Hongqiao International Airport</td>\n",
       "      <td>10.0</td>\n",
       "      <td>AS</td>\n",
       "      <td>CN</td>\n",
       "      <td>CN-31</td>\n",
       "      <td>Shanghai</td>\n",
       "      <td>ZSSS</td>\n",
       "      <td>SHA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>121.33599853515625, 31.197900772094727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54954</th>\n",
       "      <td>ZUCK</td>\n",
       "      <td>large_airport</td>\n",
       "      <td>Chongqing Jiangbei International Airport</td>\n",
       "      <td>1365.0</td>\n",
       "      <td>AS</td>\n",
       "      <td>CN</td>\n",
       "      <td>CN-50</td>\n",
       "      <td>Chongqing</td>\n",
       "      <td>ZUCK</td>\n",
       "      <td>CKG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106.64199829101562, 29.719200134277344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54959</th>\n",
       "      <td>ZUGY</td>\n",
       "      <td>large_airport</td>\n",
       "      <td>Longdongbao Airport</td>\n",
       "      <td>3736.0</td>\n",
       "      <td>AS</td>\n",
       "      <td>CN</td>\n",
       "      <td>CN-52</td>\n",
       "      <td>Guiyang</td>\n",
       "      <td>ZUGY</td>\n",
       "      <td>KWE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106.8010025024414, 26.53849983215332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54982</th>\n",
       "      <td>ZUZY</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>Zunyi Xinzhou Airport</td>\n",
       "      <td>2920.0</td>\n",
       "      <td>AS</td>\n",
       "      <td>CN</td>\n",
       "      <td>CN-52</td>\n",
       "      <td>Zunyi</td>\n",
       "      <td>ZUZY</td>\n",
       "      <td>ZYI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>107.0007, 27.5895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54997</th>\n",
       "      <td>ZW-0015</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Maronga Airport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AF</td>\n",
       "      <td>ZW</td>\n",
       "      <td>ZW-MW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.427123, -16.855435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54999</th>\n",
       "      <td>ZW-0017</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lake Kariba Airport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AF</td>\n",
       "      <td>ZW</td>\n",
       "      <td>ZW-MN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.635, -17.345659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55000</th>\n",
       "      <td>ZW-0018</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Sijarira Lodge Airstrip</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AF</td>\n",
       "      <td>ZW</td>\n",
       "      <td>ZW-MN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.500593, -17.51631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55001</th>\n",
       "      <td>ZW-0019</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Manjolo Airport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AF</td>\n",
       "      <td>ZW</td>\n",
       "      <td>ZW-MN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.171634, -17.814685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55005</th>\n",
       "      <td>ZW-0023</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Peoza Pasi Airstrip</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AF</td>\n",
       "      <td>ZW</td>\n",
       "      <td>ZW-MC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.396064, -15.977261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55006</th>\n",
       "      <td>ZW-0024</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Chapoto Road Airstrip</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AF</td>\n",
       "      <td>ZW</td>\n",
       "      <td>ZW-MC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.402576, -15.749968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55008</th>\n",
       "      <td>ZW-0026</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Mucumbura River Airport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AF</td>\n",
       "      <td>ZW</td>\n",
       "      <td>ZW-MC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.681177, -16.205187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55009</th>\n",
       "      <td>ZW-0027</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Mwanja River Airport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AF</td>\n",
       "      <td>ZW</td>\n",
       "      <td>ZW-MW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.9871, -15.64811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55010</th>\n",
       "      <td>ZW-0028</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Chewore Lodge Airstrip</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AF</td>\n",
       "      <td>ZW</td>\n",
       "      <td>ZW-MW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.879651, -15.647438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55011</th>\n",
       "      <td>ZW-0029</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Chikwenya Game Lodge Airstrip</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AF</td>\n",
       "      <td>ZW</td>\n",
       "      <td>ZW-MW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.576598, -15.6956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55012</th>\n",
       "      <td>ZW-0030</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Rukomeshe Research Station Airstrip</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AF</td>\n",
       "      <td>ZW</td>\n",
       "      <td>ZW-MW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FVRK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.415766, -16.147148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55014</th>\n",
       "      <td>ZW-0032</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Chewonde Airport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AF</td>\n",
       "      <td>ZW</td>\n",
       "      <td>ZW-MN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.270602, -17.958974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55015</th>\n",
       "      <td>ZW-0033</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Sengwa Airport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AF</td>\n",
       "      <td>ZW</td>\n",
       "      <td>ZW-MN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.235588, -18.167161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55016</th>\n",
       "      <td>ZW-0034</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Sengwa Research Area Airstrip</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AF</td>\n",
       "      <td>ZW</td>\n",
       "      <td>ZW-MN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.215618, -18.165196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55017</th>\n",
       "      <td>ZW-0035</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Gokwe North Airport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AF</td>\n",
       "      <td>ZW</td>\n",
       "      <td>ZW-MI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.330871, -17.537114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55020</th>\n",
       "      <td>ZW-0038</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Chipinge Farm Airstrip</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AF</td>\n",
       "      <td>ZW</td>\n",
       "      <td>ZW-MV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.203607, -20.460575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55021</th>\n",
       "      <td>ZW-0039</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Turwi River Airstrip</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AF</td>\n",
       "      <td>ZW</td>\n",
       "      <td>ZW-MV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.10904, -20.395009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55024</th>\n",
       "      <td>ZW-0042</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Sipepa Airstrip</td>\n",
       "      <td>3270.0</td>\n",
       "      <td>AF</td>\n",
       "      <td>ZW</td>\n",
       "      <td>ZW-U-A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.648321, -19.280942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55046</th>\n",
       "      <td>ZYCC</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>Longjia Airport</td>\n",
       "      <td>706.0</td>\n",
       "      <td>AS</td>\n",
       "      <td>CN</td>\n",
       "      <td>CN-22</td>\n",
       "      <td>Changchun</td>\n",
       "      <td>ZYCC</td>\n",
       "      <td>CGQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125.684997559, 43.9962005615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55052</th>\n",
       "      <td>ZYHB</td>\n",
       "      <td>large_airport</td>\n",
       "      <td>Taiping Airport</td>\n",
       "      <td>457.0</td>\n",
       "      <td>AS</td>\n",
       "      <td>CN</td>\n",
       "      <td>CN-23</td>\n",
       "      <td>Harbin</td>\n",
       "      <td>ZYHB</td>\n",
       "      <td>HRB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>126.25, 45.6234016418457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55058</th>\n",
       "      <td>ZYJZ</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>Jinzhou Airport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AS</td>\n",
       "      <td>CN</td>\n",
       "      <td>CN-21</td>\n",
       "      <td>Jinzhou</td>\n",
       "      <td>ZYJZ</td>\n",
       "      <td>JNZ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>121.06199645996094, 41.10139846801758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55062</th>\n",
       "      <td>ZYMH</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>Gu-Lian Airport</td>\n",
       "      <td>1836.0</td>\n",
       "      <td>AS</td>\n",
       "      <td>CN</td>\n",
       "      <td>CN-23</td>\n",
       "      <td>Mohe</td>\n",
       "      <td>ZYMH</td>\n",
       "      <td>OHE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>122.43, 52.912777777799995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55066</th>\n",
       "      <td>ZYTL</td>\n",
       "      <td>large_airport</td>\n",
       "      <td>Zhoushuizi Airport</td>\n",
       "      <td>107.0</td>\n",
       "      <td>AS</td>\n",
       "      <td>CN</td>\n",
       "      <td>CN-21</td>\n",
       "      <td>Dalian</td>\n",
       "      <td>ZYTL</td>\n",
       "      <td>DLC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>121.53900146484375, 38.9656982421875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55068</th>\n",
       "      <td>ZYTX</td>\n",
       "      <td>large_airport</td>\n",
       "      <td>Taoxian Airport</td>\n",
       "      <td>198.0</td>\n",
       "      <td>AS</td>\n",
       "      <td>CN</td>\n",
       "      <td>CN-21</td>\n",
       "      <td>Shenyang</td>\n",
       "      <td>ZYTX</td>\n",
       "      <td>SHE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123.48300170898438, 41.639801025390625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55071</th>\n",
       "      <td>ZYYY</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>Shenyang Dongta Airport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AS</td>\n",
       "      <td>CN</td>\n",
       "      <td>CN-21</td>\n",
       "      <td>Shenyang</td>\n",
       "      <td>ZYYY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123.49600219726562, 41.784400939941406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22464 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ident            type                                      name  \\\n",
       "49        00TE        heliport            Tcjc-Northeast Campus Heliport   \n",
       "116       01TS          closed               St Joseph Hospital Heliport   \n",
       "179       02TE        heliport            Baylor Medical Center Heliport   \n",
       "181       02TS          closed                            FWOMC Heliport   \n",
       "221       03MT   small_airport                             Cascade Field   \n",
       "231       03OH   small_airport                               Gibbs Field   \n",
       "238       03PS          closed                             Ziggy's Field   \n",
       "312       05AK   small_airport                     Wasilla Creek Airpark   \n",
       "327       05II   small_airport                         Reichhart Airport   \n",
       "353       05PA        heliport                        PECO Mob. Heliport   \n",
       "366       05WA        heliport      Sacred Heart Medical Center Helistop   \n",
       "405       06NH   small_airport                         Cole Farm Airport   \n",
       "407       06NV   small_airport                      Silver Creek Airport   \n",
       "413       06OR   small_airport                   Hayden Mountain Airport   \n",
       "415       06PN        heliport                        Schiavoni Heliport   \n",
       "425       06WA        heliport              N A Degerstrom Yard Heliport   \n",
       "430       07AA   small_airport                    Pan Lake Strip Airport   \n",
       "464       07NV   small_airport                  Border Line Farm Airport   \n",
       "474       07TS   small_airport             Cross-Country Estates Airport   \n",
       "479       07WA        heliport     Multicare Deaconess Hospital Heliport   \n",
       "493       08FA   small_airport                             Duda Airstrip   \n",
       "494       08FD   small_airport                   Sunniland Ranch Airport   \n",
       "495       08FL   small_airport               J. H. Hendrie Farms Airport   \n",
       "505       08LA        heliport                 Air Oil Inc Nr 2 Heliport   \n",
       "522       08NY   small_airport                               Md1 Airport   \n",
       "526       08OR   small_airport                       Saxon Sycan Airport   \n",
       "541       09AK   small_airport                       West Beaver Airport   \n",
       "546       09CN        heliport           Tulare Motor Sports #2 Heliport   \n",
       "548       09FA   small_airport                      Placid Lakes Airport   \n",
       "549       09FD   small_airport              Cheryl-Lane Landings Airport   \n",
       "...        ...             ...                                       ...   \n",
       "54929     ZSPD   large_airport     Shanghai Pudong International Airport   \n",
       "54934     ZSSS   large_airport   Shanghai Hongqiao International Airport   \n",
       "54954     ZUCK   large_airport  Chongqing Jiangbei International Airport   \n",
       "54959     ZUGY   large_airport                       Longdongbao Airport   \n",
       "54982     ZUZY  medium_airport                     Zunyi Xinzhou Airport   \n",
       "54997  ZW-0015   small_airport                           Maronga Airport   \n",
       "54999  ZW-0017   small_airport                       Lake Kariba Airport   \n",
       "55000  ZW-0018   small_airport                   Sijarira Lodge Airstrip   \n",
       "55001  ZW-0019   small_airport                           Manjolo Airport   \n",
       "55005  ZW-0023   small_airport                       Peoza Pasi Airstrip   \n",
       "55006  ZW-0024   small_airport                     Chapoto Road Airstrip   \n",
       "55008  ZW-0026   small_airport                   Mucumbura River Airport   \n",
       "55009  ZW-0027   small_airport                      Mwanja River Airport   \n",
       "55010  ZW-0028   small_airport                    Chewore Lodge Airstrip   \n",
       "55011  ZW-0029   small_airport             Chikwenya Game Lodge Airstrip   \n",
       "55012  ZW-0030   small_airport       Rukomeshe Research Station Airstrip   \n",
       "55014  ZW-0032   small_airport                          Chewonde Airport   \n",
       "55015  ZW-0033   small_airport                            Sengwa Airport   \n",
       "55016  ZW-0034   small_airport             Sengwa Research Area Airstrip   \n",
       "55017  ZW-0035   small_airport                       Gokwe North Airport   \n",
       "55020  ZW-0038   small_airport                    Chipinge Farm Airstrip   \n",
       "55021  ZW-0039   small_airport                      Turwi River Airstrip   \n",
       "55024  ZW-0042   small_airport                           Sipepa Airstrip   \n",
       "55046     ZYCC  medium_airport                           Longjia Airport   \n",
       "55052     ZYHB   large_airport                           Taiping Airport   \n",
       "55058     ZYJZ  medium_airport                           Jinzhou Airport   \n",
       "55062     ZYMH  medium_airport                           Gu-Lian Airport   \n",
       "55066     ZYTL   large_airport                        Zhoushuizi Airport   \n",
       "55068     ZYTX   large_airport                           Taoxian Airport   \n",
       "55071     ZYYY  medium_airport                   Shenyang Dongta Airport   \n",
       "\n",
       "       elevation_ft continent iso_country iso_region  municipality gps_code  \\\n",
       "49            600.0       NaN          US      US-TX    Fort Worth     00TE   \n",
       "116           675.0       NaN          US      US-TX    Fort Worth      NaN   \n",
       "179           560.0       NaN          US      US-TX    Waxahachie     02TE   \n",
       "181           684.0       NaN          US      US-TX    Fort Worth      NaN   \n",
       "221          3580.0       NaN          US      US-MT       Cascade     3MT7   \n",
       "231           580.0       NaN          US      US-OH       Fremont     03OH   \n",
       "238          1050.0       NaN          US      US-PA    Bellefonte      NaN   \n",
       "312           620.0       NaN          US      US-AK        Palmer     05AK   \n",
       "327           795.0       NaN          US      US-IN     New Haven     05II   \n",
       "353           110.0       NaN          US      US-PA  Philadelphia     05PA   \n",
       "366          2220.0       NaN          US      US-WA       Spokane     05WA   \n",
       "405           160.0       NaN          US      US-NH    Kensington     06NH   \n",
       "407          5556.0       NaN          US      US-NV         Baker     06NV   \n",
       "413           850.0       NaN          US      US-OR  Forest Grove     06OR   \n",
       "415           727.0       NaN          US      US-PA    Harrisburg     06PN   \n",
       "425          2013.0       NaN          US      US-WA       Spokane     06WA   \n",
       "430           357.0       NaN          US      US-AK        Willow     07AA   \n",
       "464          5120.0       NaN          US      US-NV         Baker     07NV   \n",
       "474           690.0       NaN          US      US-TX    Georgetown     07TS   \n",
       "479          2110.0       NaN          US      US-WA       Spokane     07WA   \n",
       "493            35.0       NaN          US      US-FL      La Belle     08FA   \n",
       "494            65.0       NaN          US      US-FL    Okeechobee     08FD   \n",
       "495           103.0       NaN          US      US-FL   Lake Placid     08FL   \n",
       "505             4.0       NaN          US      US-LA       Harahan     08LA   \n",
       "522           650.0       NaN          US      US-NY    Middletown     08NY   \n",
       "526          4990.0       NaN          US      US-OR   Silver Lake     08OR   \n",
       "541           228.0       NaN          US      US-AK      Big Lake     09AK   \n",
       "546           272.0       NaN          US      US-CA        Tulare     09CN   \n",
       "548           130.0       NaN          US      US-FL   Lake Placid     09FA   \n",
       "549            71.0       NaN          US      US-FL      Bushnell     09FD   \n",
       "...             ...       ...         ...        ...           ...      ...   \n",
       "54929          13.0        AS          CN      CN-31      Shanghai     ZSPD   \n",
       "54934          10.0        AS          CN      CN-31      Shanghai     ZSSS   \n",
       "54954        1365.0        AS          CN      CN-50     Chongqing     ZUCK   \n",
       "54959        3736.0        AS          CN      CN-52       Guiyang     ZUGY   \n",
       "54982        2920.0        AS          CN      CN-52         Zunyi     ZUZY   \n",
       "54997           NaN        AF          ZW      ZW-MW           NaN      NaN   \n",
       "54999           NaN        AF          ZW      ZW-MN           NaN      NaN   \n",
       "55000           NaN        AF          ZW      ZW-MN           NaN      NaN   \n",
       "55001           NaN        AF          ZW      ZW-MN           NaN      NaN   \n",
       "55005           NaN        AF          ZW      ZW-MC           NaN      NaN   \n",
       "55006           NaN        AF          ZW      ZW-MC           NaN      NaN   \n",
       "55008           NaN        AF          ZW      ZW-MC           NaN      NaN   \n",
       "55009           NaN        AF          ZW      ZW-MW           NaN      NaN   \n",
       "55010           NaN        AF          ZW      ZW-MW           NaN      NaN   \n",
       "55011           NaN        AF          ZW      ZW-MW           NaN      NaN   \n",
       "55012           NaN        AF          ZW      ZW-MW           NaN     FVRK   \n",
       "55014           NaN        AF          ZW      ZW-MN           NaN      NaN   \n",
       "55015           NaN        AF          ZW      ZW-MN           NaN      NaN   \n",
       "55016           NaN        AF          ZW      ZW-MN           NaN      NaN   \n",
       "55017           NaN        AF          ZW      ZW-MI           NaN      NaN   \n",
       "55020           NaN        AF          ZW      ZW-MV           NaN      NaN   \n",
       "55021           NaN        AF          ZW      ZW-MV           NaN      NaN   \n",
       "55024        3270.0        AF          ZW     ZW-U-A           NaN      NaN   \n",
       "55046         706.0        AS          CN      CN-22     Changchun     ZYCC   \n",
       "55052         457.0        AS          CN      CN-23        Harbin     ZYHB   \n",
       "55058           NaN        AS          CN      CN-21       Jinzhou     ZYJZ   \n",
       "55062        1836.0        AS          CN      CN-23          Mohe     ZYMH   \n",
       "55066         107.0        AS          CN      CN-21        Dalian     ZYTL   \n",
       "55068         198.0        AS          CN      CN-21      Shenyang     ZYTX   \n",
       "55071           NaN        AS          CN      CN-21      Shenyang     ZYYY   \n",
       "\n",
       "      iata_code local_code                              coordinates  \n",
       "49          NaN       00TE   -97.18949890136719, 32.847599029541016  \n",
       "116         NaN        NaN                      -97.324501, 32.7285  \n",
       "179         NaN       02TE    -96.86419677734375, 32.39540100097656  \n",
       "181         NaN        NaN                    -97.370003, 32.747601  \n",
       "221         NaN       3MT7                    -111.71748, 47.267327  \n",
       "231         NaN       03OH   -83.01740264892578, 41.418399810791016  \n",
       "238         NaN        NaN                    -77.905602, 40.849998  \n",
       "312         NaN       05AK                -149.1880035, 61.66830063  \n",
       "327         NaN       05II    -84.99720001220703, 41.02870178222656  \n",
       "353         NaN       05PA                      -75.178201, 39.9548  \n",
       "366         NaN       05WA   -117.41400146484375, 47.64820098876953  \n",
       "405         NaN       06NH    -70.97309875488281, 42.92839813232422  \n",
       "407         NaN       06NV                   -114.150277, 39.098333  \n",
       "413         NaN       06OR    -123.08000183105469, 45.4650993347168  \n",
       "415         NaN       06PN                    -76.772533, 40.382733  \n",
       "425         NaN       06WA     -117.197998046875, 47.68629837036133  \n",
       "430         NaN       07AA                 -149.9549028, 61.6959639  \n",
       "464         NaN       07NV                   -114.053472, 39.102239  \n",
       "474         NaN       07TS               -97.57279968261719, 30.625  \n",
       "479         NaN       07WA                   -117.424477, 47.651637  \n",
       "493         NaN       08FA    -81.48370361328125, 26.57979965209961  \n",
       "494         NaN       08FD   -80.77279663085938, 27.363100051879883  \n",
       "495         NaN       08FL    -81.32869720458984, 27.08449935913086  \n",
       "505         NaN       08LA   -90.18260192871094, 29.952999114990234  \n",
       "522         NaN       08NY   -74.50559997558594, 41.368099212646484  \n",
       "526         NaN       08OR  -121.11699676513672, 42.839298248291016  \n",
       "541         NaN       09AK                   -149.847333, 61.589361  \n",
       "546         NaN       09CN                   -119.313572, 36.182556  \n",
       "548         NaN       09FA     -81.41310119628906, 27.2455997467041  \n",
       "549         NaN       09FD    -82.0873031616211, 28.671100616455078  \n",
       "...         ...        ...                                      ...  \n",
       "54929       PVG        NaN   121.80500030517578, 31.143400192260742  \n",
       "54934       SHA        NaN   121.33599853515625, 31.197900772094727  \n",
       "54954       CKG        NaN   106.64199829101562, 29.719200134277344  \n",
       "54959       KWE        NaN     106.8010025024414, 26.53849983215332  \n",
       "54982       ZYI        NaN                        107.0007, 27.5895  \n",
       "54997       NaN        NaN                    28.427123, -16.855435  \n",
       "54999       NaN        NaN                       27.635, -17.345659  \n",
       "55000       NaN        NaN                     27.500593, -17.51631  \n",
       "55001       NaN        NaN                    27.171634, -17.814685  \n",
       "55005       NaN        NaN                    30.396064, -15.977261  \n",
       "55006       NaN        NaN                    30.402576, -15.749968  \n",
       "55008       NaN        NaN                    31.681177, -16.205187  \n",
       "55009       NaN        NaN                       29.9871, -15.64811  \n",
       "55010       NaN        NaN                    29.879651, -15.647438  \n",
       "55011       NaN        NaN                      29.576598, -15.6956  \n",
       "55012       NaN        NaN                    29.415766, -16.147148  \n",
       "55014       NaN        NaN                    28.270602, -17.958974  \n",
       "55015       NaN        NaN                    28.235588, -18.167161  \n",
       "55016       NaN        NaN                    28.215618, -18.165196  \n",
       "55017       NaN        NaN                    28.330871, -17.537114  \n",
       "55020       NaN        NaN                    32.203607, -20.460575  \n",
       "55021       NaN        NaN                     32.10904, -20.395009  \n",
       "55024       NaN        NaN                    27.648321, -19.280942  \n",
       "55046       CGQ        NaN             125.684997559, 43.9962005615  \n",
       "55052       HRB        NaN                 126.25, 45.6234016418457  \n",
       "55058       JNZ        NaN    121.06199645996094, 41.10139846801758  \n",
       "55062       OHE        NaN               122.43, 52.912777777799995  \n",
       "55066       DLC        NaN     121.53900146484375, 38.9656982421875  \n",
       "55068       SHE        NaN   123.48300170898438, 41.639801025390625  \n",
       "55071       NaN        NaN   123.49600219726562, 41.784400939941406  \n",
       "\n",
       "[22464 rows x 12 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ident               0\n",
       "type                0\n",
       "name                0\n",
       "elevation_ft     7006\n",
       "continent       27719\n",
       "iso_country       247\n",
       "iso_region          0\n",
       "municipality     5676\n",
       "gps_code        14045\n",
       "iata_code       45886\n",
       "local_code      26389\n",
       "coordinates         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23699</th>\n",
       "      <td>ID31</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Young Heliport</td>\n",
       "      <td>2625.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-ID</td>\n",
       "      <td>Eagle</td>\n",
       "      <td>ID31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ID31</td>\n",
       "      <td>-116.38899993896484, 43.71659851074219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27016</th>\n",
       "      <td>KEGE</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>Eagle County Regional Airport</td>\n",
       "      <td>6548.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-CO</td>\n",
       "      <td>Eagle</td>\n",
       "      <td>KEGE</td>\n",
       "      <td>EGE</td>\n",
       "      <td>EGE</td>\n",
       "      <td>-106.9179993, 39.64260101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38243</th>\n",
       "      <td>PAEG</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Eagle Airport</td>\n",
       "      <td>908.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Eagle</td>\n",
       "      <td>PAEG</td>\n",
       "      <td>EAA</td>\n",
       "      <td>EAA</td>\n",
       "      <td>-141.151001, 64.77639771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ident            type                           name  elevation_ft  \\\n",
       "23699  ID31        heliport                 Young Heliport        2625.0   \n",
       "27016  KEGE  medium_airport  Eagle County Regional Airport        6548.0   \n",
       "38243  PAEG   small_airport                  Eagle Airport         908.0   \n",
       "\n",
       "      continent iso_country iso_region municipality gps_code iata_code  \\\n",
       "23699       NaN          US      US-ID        Eagle     ID31       NaN   \n",
       "27016       NaN          US      US-CO        Eagle     KEGE       EGE   \n",
       "38243       NaN          US      US-AK        Eagle     PAEG       EAA   \n",
       "\n",
       "      local_code                             coordinates  \n",
       "23699       ID31  -116.38899993896484, 43.71659851074219  \n",
       "27016        EGE               -106.9179993, 39.64260101  \n",
       "38243        EAA                -141.151001, 64.77639771  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_df[airport_df['municipality']=='Eagle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask=airport_df['municipality'].str.contains('DOUGLAS',case=False, na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20457</th>\n",
       "      <td>FK-0024</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Douglas Station Airport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SA</td>\n",
       "      <td>FK</td>\n",
       "      <td>FK-U-A</td>\n",
       "      <td>Douglas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-58.612131, -51.459942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6747</th>\n",
       "      <td>60KS</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Alley Field</td>\n",
       "      <td>1260.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Douglass</td>\n",
       "      <td>60KS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60KS</td>\n",
       "      <td>-97.00029754638672, 37.51390075683594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4273</th>\n",
       "      <td>3GE6</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Wellstar Douglas Hospital Heliport</td>\n",
       "      <td>1120.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-GA</td>\n",
       "      <td>Douglasville</td>\n",
       "      <td>3GE6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3GE6</td>\n",
       "      <td>-84.73280334472656, 33.73889923095703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ident           type                                name  \\\n",
       "20457  FK-0024  small_airport             Douglas Station Airport   \n",
       "6747      60KS  small_airport                         Alley Field   \n",
       "4273      3GE6       heliport  Wellstar Douglas Hospital Heliport   \n",
       "\n",
       "       elevation_ft continent iso_country iso_region  municipality gps_code  \\\n",
       "20457           NaN        SA          FK     FK-U-A       Douglas      NaN   \n",
       "6747         1260.0       NaN          US      US-KS      Douglass     60KS   \n",
       "4273         1120.0       NaN          US      US-GA  Douglasville     3GE6   \n",
       "\n",
       "      iata_code local_code                            coordinates  \n",
       "20457       NaN        NaN                 -58.612131, -51.459942  \n",
       "6747        NaN       60KS  -97.00029754638672, 37.51390075683594  \n",
       "4273        NaN       3GE6  -84.73280334472656, 33.73889923095703  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_df[mask].sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "small_airport     33965\n",
       "heliport          11287\n",
       "medium_airport     4550\n",
       "closed             3606\n",
       "seaplane_base      1016\n",
       "large_airport       627\n",
       "balloonport          24\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_df.type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22757"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(airport_df[airport_df['iso_country']=='US'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ident            0.000000\n",
       "type             0.000000\n",
       "name             0.000000\n",
       "elevation_ft    12.720835\n",
       "continent       50.329551\n",
       "iso_country      0.448479\n",
       "iso_region       0.000000\n",
       "municipality    10.305946\n",
       "gps_code        25.501589\n",
       "iata_code       83.315479\n",
       "local_code      47.914662\n",
       "coordinates      0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_per = airport_df.isnull().sum()/airport_df.shape[0]*100\n",
    "null_per"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['iata_code'], dtype='object')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_columns = null_per[null_per>80].keys()\n",
    "drop_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = airport_df.drop(drop_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df['State_code'] = output_df.iso_region.str.split('-', expand = True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.loc[output_df[\"iso_country\"].isna(), \"iso_country\"] = output_df.iso_region.str.split('-', expand = True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping0 = output_df.dropna().drop_duplicates().set_index(\"iso_country\")[\"continent\"].to_dict()\n",
    "output_df.loc[output_df[\"continent\"].isna(), \"continent\"] = output_df.loc[output_df[\"continent\"].isna(), \"iso_country\"].map(mapping0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.loc[output_df[\"gps_code\"].isna(), \"gps_code\"] = output_df[\"ident\"]\n",
    "output_df.loc[output_df[\"local_code\"].isna(), \"local_code\"] = output_df[\"gps_code\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ident            0.000000\n",
       "type             0.000000\n",
       "name             0.000000\n",
       "elevation_ft    12.720835\n",
       "continent        9.009532\n",
       "iso_country      0.000000\n",
       "iso_region       0.000000\n",
       "municipality    10.305946\n",
       "gps_code         0.000000\n",
       "local_code       0.000000\n",
       "coordinates      0.000000\n",
       "State_code       0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.isnull().sum()/output_df.shape[0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ident           0.000000\n",
       "type            0.000000\n",
       "name            0.000000\n",
       "elevation_ft    0.433954\n",
       "continent       0.000000\n",
       "iso_country     0.000000\n",
       "iso_region      0.000000\n",
       "municipality    0.185202\n",
       "gps_code        0.000000\n",
       "local_code      0.000000\n",
       "coordinates     0.000000\n",
       "State_code      0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df[output_df['iso_country']=='US'].isnull().sum()/output_df.shape[0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.dropna(axis=0,subset=[\"municipality\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49399"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = '../../data2/GlobalLandTemperaturesByCity.csv'\n",
    "df = pd.read_csv(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.737</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt  AverageTemperature  AverageTemperatureUncertainty   City  \\\n",
       "0  1743-11-01               6.068                          1.737  Århus   \n",
       "1  1743-12-01                 NaN                            NaN  Århus   \n",
       "2  1744-01-01                 NaN                            NaN  Århus   \n",
       "3  1744-02-01                 NaN                            NaN  Århus   \n",
       "4  1744-03-01                 NaN                            NaN  Århus   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8599212 entries, 0 to 8599211\n",
      "Data columns (total 7 columns):\n",
      "dt                               object\n",
      "AverageTemperature               float64\n",
      "AverageTemperatureUncertainty    float64\n",
      "City                             object\n",
      "Country                          object\n",
      "Latitude                         object\n",
      "Longitude                        object\n",
      "dtypes: float64(2), object(5)\n",
      "memory usage: 459.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate = df[df.duplicated(['dt'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3239</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>10.013</td>\n",
       "      <td>2.291</td>\n",
       "      <td>Çorlu</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>40.99N</td>\n",
       "      <td>27.69E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3240</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Çorlu</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>40.99N</td>\n",
       "      <td>27.69E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3241</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Çorlu</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>40.99N</td>\n",
       "      <td>27.69E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3242</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Çorlu</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>40.99N</td>\n",
       "      <td>27.69E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3243</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Çorlu</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>40.99N</td>\n",
       "      <td>27.69E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3244</th>\n",
       "      <td>1744-04-01</td>\n",
       "      <td>13.685</td>\n",
       "      <td>2.162</td>\n",
       "      <td>Çorlu</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>40.99N</td>\n",
       "      <td>27.69E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3245</th>\n",
       "      <td>1744-05-01</td>\n",
       "      <td>15.021</td>\n",
       "      <td>1.824</td>\n",
       "      <td>Çorlu</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>40.99N</td>\n",
       "      <td>27.69E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3246</th>\n",
       "      <td>1744-06-01</td>\n",
       "      <td>19.663</td>\n",
       "      <td>1.701</td>\n",
       "      <td>Çorlu</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>40.99N</td>\n",
       "      <td>27.69E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3247</th>\n",
       "      <td>1744-07-01</td>\n",
       "      <td>22.314</td>\n",
       "      <td>1.648</td>\n",
       "      <td>Çorlu</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>40.99N</td>\n",
       "      <td>27.69E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3248</th>\n",
       "      <td>1744-08-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Çorlu</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>40.99N</td>\n",
       "      <td>27.69E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3249</th>\n",
       "      <td>1744-09-01</td>\n",
       "      <td>18.682</td>\n",
       "      <td>1.895</td>\n",
       "      <td>Çorlu</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>40.99N</td>\n",
       "      <td>27.69E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3250</th>\n",
       "      <td>1744-10-01</td>\n",
       "      <td>13.540</td>\n",
       "      <td>2.105</td>\n",
       "      <td>Çorlu</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>40.99N</td>\n",
       "      <td>27.69E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3251</th>\n",
       "      <td>1744-11-01</td>\n",
       "      <td>10.447</td>\n",
       "      <td>2.223</td>\n",
       "      <td>Çorlu</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>40.99N</td>\n",
       "      <td>27.69E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3252</th>\n",
       "      <td>1744-12-01</td>\n",
       "      <td>6.126</td>\n",
       "      <td>2.314</td>\n",
       "      <td>Çorlu</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>40.99N</td>\n",
       "      <td>27.69E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3253</th>\n",
       "      <td>1745-01-01</td>\n",
       "      <td>2.810</td>\n",
       "      <td>2.351</td>\n",
       "      <td>Çorlu</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>40.99N</td>\n",
       "      <td>27.69E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3254</th>\n",
       "      <td>1745-02-01</td>\n",
       "      <td>3.879</td>\n",
       "      <td>2.286</td>\n",
       "      <td>Çorlu</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>40.99N</td>\n",
       "      <td>27.69E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3255</th>\n",
       "      <td>1745-03-01</td>\n",
       "      <td>5.553</td>\n",
       "      <td>2.167</td>\n",
       "      <td>Çorlu</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>40.99N</td>\n",
       "      <td>27.69E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3256</th>\n",
       "      <td>1745-04-01</td>\n",
       "      <td>10.926</td>\n",
       "      <td>1.935</td>\n",
       "      <td>Çorlu</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>40.99N</td>\n",
       "      <td>27.69E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3257</th>\n",
       "      <td>1745-05-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Çorlu</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>40.99N</td>\n",
       "      <td>27.69E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>1745-06-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Çorlu</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>40.99N</td>\n",
       "      <td>27.69E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>1745-07-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Çorlu</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>40.99N</td>\n",
       "      <td>27.69E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>1745-08-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Çorlu</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>40.99N</td>\n",
       "      <td>27.69E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>1745-09-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Çorlu</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>40.99N</td>\n",
       "      <td>27.69E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>1745-10-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Çorlu</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>40.99N</td>\n",
       "      <td>27.69E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3263</th>\n",
       "      <td>1745-11-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Çorlu</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>40.99N</td>\n",
       "      <td>27.69E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3264</th>\n",
       "      <td>1745-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Çorlu</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>40.99N</td>\n",
       "      <td>27.69E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3265</th>\n",
       "      <td>1746-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Çorlu</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>40.99N</td>\n",
       "      <td>27.69E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3266</th>\n",
       "      <td>1746-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Çorlu</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>40.99N</td>\n",
       "      <td>27.69E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3267</th>\n",
       "      <td>1746-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Çorlu</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>40.99N</td>\n",
       "      <td>27.69E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3268</th>\n",
       "      <td>1746-04-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Çorlu</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>40.99N</td>\n",
       "      <td>27.69E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8599182</th>\n",
       "      <td>2011-04-01</td>\n",
       "      <td>12.554</td>\n",
       "      <td>0.153</td>\n",
       "      <td>Zwolle</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>52.24N</td>\n",
       "      <td>5.26E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8599183</th>\n",
       "      <td>2011-05-01</td>\n",
       "      <td>14.066</td>\n",
       "      <td>0.149</td>\n",
       "      <td>Zwolle</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>52.24N</td>\n",
       "      <td>5.26E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8599184</th>\n",
       "      <td>2011-06-01</td>\n",
       "      <td>16.273</td>\n",
       "      <td>0.267</td>\n",
       "      <td>Zwolle</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>52.24N</td>\n",
       "      <td>5.26E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8599185</th>\n",
       "      <td>2011-07-01</td>\n",
       "      <td>16.020</td>\n",
       "      <td>0.179</td>\n",
       "      <td>Zwolle</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>52.24N</td>\n",
       "      <td>5.26E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8599186</th>\n",
       "      <td>2011-08-01</td>\n",
       "      <td>16.975</td>\n",
       "      <td>0.139</td>\n",
       "      <td>Zwolle</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>52.24N</td>\n",
       "      <td>5.26E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8599187</th>\n",
       "      <td>2011-09-01</td>\n",
       "      <td>15.788</td>\n",
       "      <td>0.109</td>\n",
       "      <td>Zwolle</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>52.24N</td>\n",
       "      <td>5.26E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8599188</th>\n",
       "      <td>2011-10-01</td>\n",
       "      <td>11.337</td>\n",
       "      <td>0.221</td>\n",
       "      <td>Zwolle</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>52.24N</td>\n",
       "      <td>5.26E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8599189</th>\n",
       "      <td>2011-11-01</td>\n",
       "      <td>6.990</td>\n",
       "      <td>0.097</td>\n",
       "      <td>Zwolle</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>52.24N</td>\n",
       "      <td>5.26E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8599190</th>\n",
       "      <td>2011-12-01</td>\n",
       "      <td>5.722</td>\n",
       "      <td>0.261</td>\n",
       "      <td>Zwolle</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>52.24N</td>\n",
       "      <td>5.26E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8599191</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>4.348</td>\n",
       "      <td>0.293</td>\n",
       "      <td>Zwolle</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>52.24N</td>\n",
       "      <td>5.26E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8599192</th>\n",
       "      <td>2012-02-01</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.290</td>\n",
       "      <td>Zwolle</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>52.24N</td>\n",
       "      <td>5.26E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8599193</th>\n",
       "      <td>2012-03-01</td>\n",
       "      <td>7.863</td>\n",
       "      <td>0.135</td>\n",
       "      <td>Zwolle</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>52.24N</td>\n",
       "      <td>5.26E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8599194</th>\n",
       "      <td>2012-04-01</td>\n",
       "      <td>8.101</td>\n",
       "      <td>0.168</td>\n",
       "      <td>Zwolle</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>52.24N</td>\n",
       "      <td>5.26E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8599195</th>\n",
       "      <td>2012-05-01</td>\n",
       "      <td>14.169</td>\n",
       "      <td>0.191</td>\n",
       "      <td>Zwolle</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>52.24N</td>\n",
       "      <td>5.26E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8599196</th>\n",
       "      <td>2012-06-01</td>\n",
       "      <td>14.702</td>\n",
       "      <td>0.342</td>\n",
       "      <td>Zwolle</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>52.24N</td>\n",
       "      <td>5.26E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8599197</th>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>17.329</td>\n",
       "      <td>0.287</td>\n",
       "      <td>Zwolle</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>52.24N</td>\n",
       "      <td>5.26E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8599198</th>\n",
       "      <td>2012-08-01</td>\n",
       "      <td>18.588</td>\n",
       "      <td>0.224</td>\n",
       "      <td>Zwolle</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>52.24N</td>\n",
       "      <td>5.26E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8599199</th>\n",
       "      <td>2012-09-01</td>\n",
       "      <td>14.333</td>\n",
       "      <td>0.207</td>\n",
       "      <td>Zwolle</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>52.24N</td>\n",
       "      <td>5.26E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8599200</th>\n",
       "      <td>2012-10-01</td>\n",
       "      <td>10.358</td>\n",
       "      <td>0.208</td>\n",
       "      <td>Zwolle</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>52.24N</td>\n",
       "      <td>5.26E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8599201</th>\n",
       "      <td>2012-11-01</td>\n",
       "      <td>6.469</td>\n",
       "      <td>0.189</td>\n",
       "      <td>Zwolle</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>52.24N</td>\n",
       "      <td>5.26E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8599202</th>\n",
       "      <td>2012-12-01</td>\n",
       "      <td>4.303</td>\n",
       "      <td>0.341</td>\n",
       "      <td>Zwolle</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>52.24N</td>\n",
       "      <td>5.26E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8599203</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1.479</td>\n",
       "      <td>0.217</td>\n",
       "      <td>Zwolle</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>52.24N</td>\n",
       "      <td>5.26E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8599204</th>\n",
       "      <td>2013-02-01</td>\n",
       "      <td>1.559</td>\n",
       "      <td>0.304</td>\n",
       "      <td>Zwolle</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>52.24N</td>\n",
       "      <td>5.26E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8599205</th>\n",
       "      <td>2013-03-01</td>\n",
       "      <td>2.253</td>\n",
       "      <td>0.267</td>\n",
       "      <td>Zwolle</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>52.24N</td>\n",
       "      <td>5.26E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8599206</th>\n",
       "      <td>2013-04-01</td>\n",
       "      <td>7.710</td>\n",
       "      <td>0.182</td>\n",
       "      <td>Zwolle</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>52.24N</td>\n",
       "      <td>5.26E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8599207</th>\n",
       "      <td>2013-05-01</td>\n",
       "      <td>11.464</td>\n",
       "      <td>0.236</td>\n",
       "      <td>Zwolle</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>52.24N</td>\n",
       "      <td>5.26E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8599208</th>\n",
       "      <td>2013-06-01</td>\n",
       "      <td>15.043</td>\n",
       "      <td>0.261</td>\n",
       "      <td>Zwolle</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>52.24N</td>\n",
       "      <td>5.26E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8599209</th>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>18.775</td>\n",
       "      <td>0.193</td>\n",
       "      <td>Zwolle</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>52.24N</td>\n",
       "      <td>5.26E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8599210</th>\n",
       "      <td>2013-08-01</td>\n",
       "      <td>18.025</td>\n",
       "      <td>0.298</td>\n",
       "      <td>Zwolle</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>52.24N</td>\n",
       "      <td>5.26E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8599211</th>\n",
       "      <td>2013-09-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zwolle</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>52.24N</td>\n",
       "      <td>5.26E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8595973 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 dt  AverageTemperature  AverageTemperatureUncertainty  \\\n",
       "3239     1743-11-01              10.013                          2.291   \n",
       "3240     1743-12-01                 NaN                            NaN   \n",
       "3241     1744-01-01                 NaN                            NaN   \n",
       "3242     1744-02-01                 NaN                            NaN   \n",
       "3243     1744-03-01                 NaN                            NaN   \n",
       "3244     1744-04-01              13.685                          2.162   \n",
       "3245     1744-05-01              15.021                          1.824   \n",
       "3246     1744-06-01              19.663                          1.701   \n",
       "3247     1744-07-01              22.314                          1.648   \n",
       "3248     1744-08-01                 NaN                            NaN   \n",
       "3249     1744-09-01              18.682                          1.895   \n",
       "3250     1744-10-01              13.540                          2.105   \n",
       "3251     1744-11-01              10.447                          2.223   \n",
       "3252     1744-12-01               6.126                          2.314   \n",
       "3253     1745-01-01               2.810                          2.351   \n",
       "3254     1745-02-01               3.879                          2.286   \n",
       "3255     1745-03-01               5.553                          2.167   \n",
       "3256     1745-04-01              10.926                          1.935   \n",
       "3257     1745-05-01                 NaN                            NaN   \n",
       "3258     1745-06-01                 NaN                            NaN   \n",
       "3259     1745-07-01                 NaN                            NaN   \n",
       "3260     1745-08-01                 NaN                            NaN   \n",
       "3261     1745-09-01                 NaN                            NaN   \n",
       "3262     1745-10-01                 NaN                            NaN   \n",
       "3263     1745-11-01                 NaN                            NaN   \n",
       "3264     1745-12-01                 NaN                            NaN   \n",
       "3265     1746-01-01                 NaN                            NaN   \n",
       "3266     1746-02-01                 NaN                            NaN   \n",
       "3267     1746-03-01                 NaN                            NaN   \n",
       "3268     1746-04-01                 NaN                            NaN   \n",
       "...             ...                 ...                            ...   \n",
       "8599182  2011-04-01              12.554                          0.153   \n",
       "8599183  2011-05-01              14.066                          0.149   \n",
       "8599184  2011-06-01              16.273                          0.267   \n",
       "8599185  2011-07-01              16.020                          0.179   \n",
       "8599186  2011-08-01              16.975                          0.139   \n",
       "8599187  2011-09-01              15.788                          0.109   \n",
       "8599188  2011-10-01              11.337                          0.221   \n",
       "8599189  2011-11-01               6.990                          0.097   \n",
       "8599190  2011-12-01               5.722                          0.261   \n",
       "8599191  2012-01-01               4.348                          0.293   \n",
       "8599192  2012-02-01               0.376                          0.290   \n",
       "8599193  2012-03-01               7.863                          0.135   \n",
       "8599194  2012-04-01               8.101                          0.168   \n",
       "8599195  2012-05-01              14.169                          0.191   \n",
       "8599196  2012-06-01              14.702                          0.342   \n",
       "8599197  2012-07-01              17.329                          0.287   \n",
       "8599198  2012-08-01              18.588                          0.224   \n",
       "8599199  2012-09-01              14.333                          0.207   \n",
       "8599200  2012-10-01              10.358                          0.208   \n",
       "8599201  2012-11-01               6.469                          0.189   \n",
       "8599202  2012-12-01               4.303                          0.341   \n",
       "8599203  2013-01-01               1.479                          0.217   \n",
       "8599204  2013-02-01               1.559                          0.304   \n",
       "8599205  2013-03-01               2.253                          0.267   \n",
       "8599206  2013-04-01               7.710                          0.182   \n",
       "8599207  2013-05-01              11.464                          0.236   \n",
       "8599208  2013-06-01              15.043                          0.261   \n",
       "8599209  2013-07-01              18.775                          0.193   \n",
       "8599210  2013-08-01              18.025                          0.298   \n",
       "8599211  2013-09-01                 NaN                            NaN   \n",
       "\n",
       "           City      Country Latitude Longitude  \n",
       "3239      Çorlu       Turkey   40.99N    27.69E  \n",
       "3240      Çorlu       Turkey   40.99N    27.69E  \n",
       "3241      Çorlu       Turkey   40.99N    27.69E  \n",
       "3242      Çorlu       Turkey   40.99N    27.69E  \n",
       "3243      Çorlu       Turkey   40.99N    27.69E  \n",
       "3244      Çorlu       Turkey   40.99N    27.69E  \n",
       "3245      Çorlu       Turkey   40.99N    27.69E  \n",
       "3246      Çorlu       Turkey   40.99N    27.69E  \n",
       "3247      Çorlu       Turkey   40.99N    27.69E  \n",
       "3248      Çorlu       Turkey   40.99N    27.69E  \n",
       "3249      Çorlu       Turkey   40.99N    27.69E  \n",
       "3250      Çorlu       Turkey   40.99N    27.69E  \n",
       "3251      Çorlu       Turkey   40.99N    27.69E  \n",
       "3252      Çorlu       Turkey   40.99N    27.69E  \n",
       "3253      Çorlu       Turkey   40.99N    27.69E  \n",
       "3254      Çorlu       Turkey   40.99N    27.69E  \n",
       "3255      Çorlu       Turkey   40.99N    27.69E  \n",
       "3256      Çorlu       Turkey   40.99N    27.69E  \n",
       "3257      Çorlu       Turkey   40.99N    27.69E  \n",
       "3258      Çorlu       Turkey   40.99N    27.69E  \n",
       "3259      Çorlu       Turkey   40.99N    27.69E  \n",
       "3260      Çorlu       Turkey   40.99N    27.69E  \n",
       "3261      Çorlu       Turkey   40.99N    27.69E  \n",
       "3262      Çorlu       Turkey   40.99N    27.69E  \n",
       "3263      Çorlu       Turkey   40.99N    27.69E  \n",
       "3264      Çorlu       Turkey   40.99N    27.69E  \n",
       "3265      Çorlu       Turkey   40.99N    27.69E  \n",
       "3266      Çorlu       Turkey   40.99N    27.69E  \n",
       "3267      Çorlu       Turkey   40.99N    27.69E  \n",
       "3268      Çorlu       Turkey   40.99N    27.69E  \n",
       "...         ...          ...      ...       ...  \n",
       "8599182  Zwolle  Netherlands   52.24N     5.26E  \n",
       "8599183  Zwolle  Netherlands   52.24N     5.26E  \n",
       "8599184  Zwolle  Netherlands   52.24N     5.26E  \n",
       "8599185  Zwolle  Netherlands   52.24N     5.26E  \n",
       "8599186  Zwolle  Netherlands   52.24N     5.26E  \n",
       "8599187  Zwolle  Netherlands   52.24N     5.26E  \n",
       "8599188  Zwolle  Netherlands   52.24N     5.26E  \n",
       "8599189  Zwolle  Netherlands   52.24N     5.26E  \n",
       "8599190  Zwolle  Netherlands   52.24N     5.26E  \n",
       "8599191  Zwolle  Netherlands   52.24N     5.26E  \n",
       "8599192  Zwolle  Netherlands   52.24N     5.26E  \n",
       "8599193  Zwolle  Netherlands   52.24N     5.26E  \n",
       "8599194  Zwolle  Netherlands   52.24N     5.26E  \n",
       "8599195  Zwolle  Netherlands   52.24N     5.26E  \n",
       "8599196  Zwolle  Netherlands   52.24N     5.26E  \n",
       "8599197  Zwolle  Netherlands   52.24N     5.26E  \n",
       "8599198  Zwolle  Netherlands   52.24N     5.26E  \n",
       "8599199  Zwolle  Netherlands   52.24N     5.26E  \n",
       "8599200  Zwolle  Netherlands   52.24N     5.26E  \n",
       "8599201  Zwolle  Netherlands   52.24N     5.26E  \n",
       "8599202  Zwolle  Netherlands   52.24N     5.26E  \n",
       "8599203  Zwolle  Netherlands   52.24N     5.26E  \n",
       "8599204  Zwolle  Netherlands   52.24N     5.26E  \n",
       "8599205  Zwolle  Netherlands   52.24N     5.26E  \n",
       "8599206  Zwolle  Netherlands   52.24N     5.26E  \n",
       "8599207  Zwolle  Netherlands   52.24N     5.26E  \n",
       "8599208  Zwolle  Netherlands   52.24N     5.26E  \n",
       "8599209  Zwolle  Netherlands   52.24N     5.26E  \n",
       "8599210  Zwolle  Netherlands   52.24N     5.26E  \n",
       "8599211  Zwolle  Netherlands   52.24N     5.26E  \n",
       "\n",
       "[8595973 rows x 7 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "India            1014906\n",
       "China             827802\n",
       "United States     687289\n",
       "Brazil            475580\n",
       "Russia            461234\n",
       "Name: Country, dtype: int64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Country.value_counts()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Springfield    9545\n",
       "Worcester      8359\n",
       "León           7469\n",
       "Rongcheng      6526\n",
       "Manchester     6478\n",
       "Name: City, dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.City.value_counts()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>539825</th>\n",
       "      <td>1833-01-01</td>\n",
       "      <td>-2.204</td>\n",
       "      <td>2.693</td>\n",
       "      <td>Baglan</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>36.17N</td>\n",
       "      <td>69.61E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539826</th>\n",
       "      <td>1833-02-01</td>\n",
       "      <td>-1.171</td>\n",
       "      <td>2.533</td>\n",
       "      <td>Baglan</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>36.17N</td>\n",
       "      <td>69.61E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539827</th>\n",
       "      <td>1833-03-01</td>\n",
       "      <td>3.459</td>\n",
       "      <td>2.799</td>\n",
       "      <td>Baglan</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>36.17N</td>\n",
       "      <td>69.61E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539828</th>\n",
       "      <td>1833-04-01</td>\n",
       "      <td>9.917</td>\n",
       "      <td>2.215</td>\n",
       "      <td>Baglan</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>36.17N</td>\n",
       "      <td>69.61E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539829</th>\n",
       "      <td>1833-05-01</td>\n",
       "      <td>15.652</td>\n",
       "      <td>2.305</td>\n",
       "      <td>Baglan</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>36.17N</td>\n",
       "      <td>69.61E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                dt  AverageTemperature  AverageTemperatureUncertainty    City  \\\n",
       "539825  1833-01-01              -2.204                          2.693  Baglan   \n",
       "539826  1833-02-01              -1.171                          2.533  Baglan   \n",
       "539827  1833-03-01               3.459                          2.799  Baglan   \n",
       "539828  1833-04-01               9.917                          2.215  Baglan   \n",
       "539829  1833-05-01              15.652                          2.305  Baglan   \n",
       "\n",
       "            Country Latitude Longitude  \n",
       "539825  Afghanistan   36.17N    69.61E  \n",
       "539826  Afghanistan   36.17N    69.61E  \n",
       "539827  Afghanistan   36.17N    69.61E  \n",
       "539828  Afghanistan   36.17N    69.61E  \n",
       "539829  Afghanistan   36.17N    69.61E  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Country']=='Afghanistan'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "687289"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df['Country']=='United States'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Springfield    9545\n",
       "Columbus       6478\n",
       "Aurora         6101\n",
       "Arlington      5564\n",
       "Peoria         5384\n",
       "Name: City, dtype: int64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Country']=='United States'].City.value_counts()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dt                               0.000000\n",
       "AverageTemperature               4.234458\n",
       "AverageTemperatureUncertainty    4.234458\n",
       "City                             0.000000\n",
       "Country                          0.000000\n",
       "Latitude                         0.000000\n",
       "Longitude                        0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_per = df.isnull().sum()/df.shape[0]*100\n",
    "null_per"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dt'] =pd.to_datetime(df['dt'], format=\"%Y-%d-%m\")\n",
    "df['year'] = df['dt'].dt.year\n",
    "df['month'] = df['dt'].dt.month\n",
    "df['week'] = df['dt'].dt.week\n",
    "df['day'] = df['dt'].dt.day\n",
    "df['dt'] = df['dt'].dt.strftime('%Y-%m-%d')\n",
    "df['dt'] =pd.to_datetime(df['dt'], format=\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8599212 entries, 0 to 8599211\n",
      "Data columns (total 11 columns):\n",
      "dt                               datetime64[ns]\n",
      "AverageTemperature               float64\n",
      "AverageTemperatureUncertainty    float64\n",
      "City                             object\n",
      "Country                          object\n",
      "Latitude                         object\n",
      "Longitude                        object\n",
      "year                             int64\n",
      "month                            int64\n",
      "week                             int64\n",
      "day                              int64\n",
      "dtypes: datetime64[ns](1), float64(2), int64(4), object(4)\n",
      "memory usage: 721.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>week</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-01-11</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.737</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "      <td>1743</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-01-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "      <td>1743</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "      <td>1744</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-01-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "      <td>1744</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-01-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "      <td>1744</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dt  AverageTemperature  AverageTemperatureUncertainty   City  \\\n",
       "0 1743-01-11               6.068                          1.737  Århus   \n",
       "1 1743-01-12                 NaN                            NaN  Århus   \n",
       "2 1744-01-01                 NaN                            NaN  Århus   \n",
       "3 1744-01-02                 NaN                            NaN  Århus   \n",
       "4 1744-01-03                 NaN                            NaN  Århus   \n",
       "\n",
       "   Country Latitude Longitude  year  month  week  day  \n",
       "0  Denmark   57.05N    10.33E  1743      1     2   11  \n",
       "1  Denmark   57.05N    10.33E  1743      1     2   12  \n",
       "2  Denmark   57.05N    10.33E  1744      1     1    1  \n",
       "3  Denmark   57.05N    10.33E  1744      1     1    2  \n",
       "4  Denmark   57.05N    10.33E  1744      1     1    3  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping1 = df.dropna().drop_duplicates().groupby([\"Country\",\"City\",\"month\",\"week\"])['AverageTemperature'].mean().to_dict()\n",
    "df.loc[df[\"AverageTemperature\"].isna(), \"AverageTemperature\"] = df.loc[df[\"AverageTemperature\"].isna(), [\"Country\",\"City\",\"month\",\"week\"]].apply(lambda x : mapping1[(x[0],x[1],x[2],x[3])],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping2 = df.dropna().drop_duplicates().groupby([\"Country\",\"City\",\"month\",\"week\"])['AverageTemperatureUncertainty'].mean().to_dict()\n",
    "df.loc[df[\"AverageTemperatureUncertainty\"].isna(), \"AverageTemperatureUncertainty\"] = df.loc[df[\"AverageTemperatureUncertainty\"].isna(), [\"Country\",\"City\",\"month\",\"week\"]].apply(lambda x : mapping2[(x[0],x[1],x[2],x[3])],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[df.year>2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "537030"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_cities_demographics = 'us-cities-demographics.csv'\n",
    "demographics_df = pd.read_csv(us_cities_demographics, header=0, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2891, 12)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographics_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2891 entries, 0 to 2890\n",
      "Data columns (total 12 columns):\n",
      "City                      2891 non-null object\n",
      "State                     2891 non-null object\n",
      "Median Age                2891 non-null float64\n",
      "Male Population           2888 non-null float64\n",
      "Female Population         2888 non-null float64\n",
      "Total Population          2891 non-null int64\n",
      "Number of Veterans        2878 non-null float64\n",
      "Foreign-born              2878 non-null float64\n",
      "Average Household Size    2875 non-null float64\n",
      "State Code                2891 non-null object\n",
      "Race                      2891 non-null object\n",
      "Count                     2891 non-null int64\n",
      "dtypes: float64(6), int64(2), object(4)\n",
      "memory usage: 271.1+ KB\n"
     ]
    }
   ],
   "source": [
    "demographics_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "California    676\n",
       "Texas         273\n",
       "Florida       222\n",
       "Name: State, dtype: int64"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographics_df.State.value_counts()[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>San Juan</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>41.4</td>\n",
       "      <td>155408.0</td>\n",
       "      <td>186829.0</td>\n",
       "      <td>342237</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PR</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>335559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Caguas</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>40.4</td>\n",
       "      <td>34743.0</td>\n",
       "      <td>42265.0</td>\n",
       "      <td>77008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PR</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>76349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>Carolina</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>42.0</td>\n",
       "      <td>64758.0</td>\n",
       "      <td>77308.0</td>\n",
       "      <td>142066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PR</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>139967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>Ponce</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>40.5</td>\n",
       "      <td>56968.0</td>\n",
       "      <td>64615.0</td>\n",
       "      <td>121583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PR</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>120705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>Bayamón</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>39.4</td>\n",
       "      <td>80128.0</td>\n",
       "      <td>90131.0</td>\n",
       "      <td>170259</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PR</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>169155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2589</th>\n",
       "      <td>Guaynabo</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>42.2</td>\n",
       "      <td>33066.0</td>\n",
       "      <td>37426.0</td>\n",
       "      <td>70492</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PR</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>69936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2746</th>\n",
       "      <td>Mayagüez</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>38.1</td>\n",
       "      <td>30799.0</td>\n",
       "      <td>35782.0</td>\n",
       "      <td>66581</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PR</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>65521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          City        State  Median Age  Male Population  Female Population  \\\n",
       "111   San Juan  Puerto Rico        41.4         155408.0           186829.0   \n",
       "155     Caguas  Puerto Rico        40.4          34743.0            42265.0   \n",
       "637   Carolina  Puerto Rico        42.0          64758.0            77308.0   \n",
       "1995     Ponce  Puerto Rico        40.5          56968.0            64615.0   \n",
       "2004   Bayamón  Puerto Rico        39.4          80128.0            90131.0   \n",
       "2589  Guaynabo  Puerto Rico        42.2          33066.0            37426.0   \n",
       "2746  Mayagüez  Puerto Rico        38.1          30799.0            35782.0   \n",
       "\n",
       "      Total Population  Number of Veterans  Foreign-born  \\\n",
       "111             342237                 NaN           NaN   \n",
       "155              77008                 NaN           NaN   \n",
       "637             142066                 NaN           NaN   \n",
       "1995            121583                 NaN           NaN   \n",
       "2004            170259                 NaN           NaN   \n",
       "2589             70492                 NaN           NaN   \n",
       "2746             66581                 NaN           NaN   \n",
       "\n",
       "      Average Household Size State Code                Race   Count  \n",
       "111                      NaN         PR  Hispanic or Latino  335559  \n",
       "155                      NaN         PR  Hispanic or Latino   76349  \n",
       "637                      NaN         PR  Hispanic or Latino  139967  \n",
       "1995                     NaN         PR  Hispanic or Latino  120705  \n",
       "2004                     NaN         PR  Hispanic or Latino  169155  \n",
       "2589                     NaN         PR  Hispanic or Latino   69936  \n",
       "2746                     NaN         PR  Hispanic or Latino   65521  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographics_df[(demographics_df[\"Race\"]==\"Hispanic or Latino\") & (demographics_df[\"State Code\"]==\"PR\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(demographics_df[(demographics_df[\"Race\"]==\"Hispanic or Latino\") & (demographics_df[\"State Code\"]==\"PR\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "City                      0.000000\n",
       "State                     0.000000\n",
       "Median Age                0.000000\n",
       "Male Population           0.103770\n",
       "Female Population         0.103770\n",
       "Total Population          0.000000\n",
       "Number of Veterans        0.449671\n",
       "Foreign-born              0.449671\n",
       "Average Household Size    0.553442\n",
       "State Code                0.000000\n",
       "Race                      0.000000\n",
       "Count                     0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_per = demographics_df.isnull().sum()/demographics_df.shape[0]*100\n",
    "null_per"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping1 = demographics_df.dropna().drop_duplicates().groupby([\"State Code\",\"Race\"])['Male Population'].mean().to_dict()\n",
    "demographics_df.loc[demographics_df[\"Male Population\"].isna(), \"Male Population\"] = demographics_df.loc[demographics_df[\"Male Population\"].isna(), [\"State Code\",\"Race\"]].apply(lambda x : mapping1[(x[0],x[1])],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics_df.loc[demographics_df[\"Female Population\"].isna(), \"Female Population\"] = demographics_df[\"Total Population\"] - demographics_df[\"Male Population\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping3 = demographics_df.dropna().drop_duplicates().groupby(\"Race\")['Foreign-born'].mean().to_dict()\n",
    "demographics_df.loc[demographics_df[\"Foreign-born\"].isna(), \"Foreign-born\"] = demographics_df.loc[demographics_df[\"Foreign-born\"].isna(), [\"Race\"]].apply(lambda x : mapping3[(x[0])],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping4 = demographics_df.dropna().drop_duplicates().groupby(\"Race\")['Average Household Size'].mean().to_dict()\n",
    "demographics_df.loc[demographics_df[\"Average Household Size\"].isna(), \"Average Household Size\"] = demographics_df.loc[demographics_df[\"Average Household Size\"].isna(), [\"Race\"]].apply(lambda x : mapping4[(x[0])],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping5 = demographics_df.dropna().drop_duplicates().groupby(\"Race\")['Number of Veterans'].mean().to_dict()\n",
    "demographics_df.loc[demographics_df[\"Number of Veterans\"].isna(), \"Number of Veterans\"] = demographics_df.loc[demographics_df[\"Number of Veterans\"].isna(), [\"Race\"]].apply(lambda x : mapping5[(x[0])],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "City                      0.0\n",
       "State                     0.0\n",
       "Median Age                0.0\n",
       "Male Population           0.0\n",
       "Female Population         0.0\n",
       "Total Population          0.0\n",
       "Number of Veterans        0.0\n",
       "Foreign-born              0.0\n",
       "Average Household Size    0.0\n",
       "State Code                0.0\n",
       "Race                      0.0\n",
       "Count                     0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_per = demographics_df.isnull().sum()/demographics_df.shape[0]*100\n",
    "null_per"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>week</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [dt, AverageTemperature, AverageTemperatureUncertainty, City, Country, Latitude, Longitude, year, month, week, day]\n",
       "Index: []"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate = df[df.duplicated()]\n",
    "duplicate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The travellers flow is my main interest, thus fact_i94 table is my fact table.\n",
    "\n",
    "- demographics_df dimension table : this dimension table is the demographical details of travellers flow based on States of US and created from the us_cities_demographics dataset. This dimension can join the fact table through the stateCode feature.\n",
    "\n",
    "- GlobalLandTemperaturesByCity dimension table: this dimension table is the temperatures  of travellers flow based on thier origin and destination countries and created from the GlobalLandTemperaturesByCity dataset. This dimension can join the fact table through the Country feature.\n",
    "\n",
    "- ArrivalDate dimension table: this dimension table is the datetime details of travellers flow based on thier Arrival and extracted and created from the i94 dataset. This dimension can join the fact table through the i94port feature.\n",
    "\n",
    "- I94Port dimension table: this dimension table is airport details of travellers flow based on State and city and this table extracted from the i94 sas_label file. This dimension can join the fact table through the i94port feature.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ModelPic](ModelPic.png){:height=\"100px\" width=\"100px\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Mapping Out Data Pipelines\n",
    "1. Clean data by dropping columns with 80% percentage of null values or more \n",
    "2. Fill the null values based on another columns \n",
    "3. Load the data into staging tables\n",
    "4. Create Dimension tables\n",
    "5. Create Fact table\n",
    "6. Write data into parquet files\n",
    "7. Perform data quality checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spark_session():\n",
    "    \"\"\"\n",
    "    the entry point of a spark application\n",
    "    \"\"\"\n",
    "    spark = SparkSession.builder.\\\n",
    "    config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\").\\\n",
    "    config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n",
    "    enableHiveSupport().getOrCreate()\n",
    "    return spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = create_spark_session()\n",
    "output_data = \"abdullahoutput/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GlobalLandTemperaturesByCity dimension table\n",
    "0. After exploring the dataset, there's no need to drop any column ,but there many steps to fill some null values and I included them within the function \n",
    "1. Read the dataset with pandas\n",
    "2. Convert \"dt\" column to date time format\n",
    "3. Extract year, month, week and day from \"dt\" column so that i can use them to fill null values\n",
    "4. Fill the null values for 'AverageTemperature' column based on \"Country\" , \"City\" , \"month\" and \"week\" columns\n",
    "5. Fill the null values for 'AverageTemperatureUncertainty' column based on \"Country\" , \"City\" , \"month\" and \"week\" columns\n",
    "6. Filter by year larger than 2000 since the dataset size is too large\n",
    "7. Create table using apache spark and fill it with the cleaned dataset\n",
    "8. Get the average of AverageTemperature and AverageTemperatureUncertainty based on the country\n",
    "9. Write the table with parquet format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GlobalLandTemperaturesByCity_fun(spark, output_data):\n",
    "    \"\"\"\n",
    "    spark: the spark session that has been created.\n",
    "    output_data: the path where the parquet files will be written.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read the dataset with pandas\n",
    "    fname = '../../data2/GlobalLandTemperaturesByCity.csv'\n",
    "    df = pd.read_csv(fname)\n",
    "    \n",
    "    # Convert \"dt\" column to date time format\n",
    "    df['dt'] =pd.to_datetime(df['dt'], format=\"%Y-%d-%m\")\n",
    "    \n",
    "    # Extract year, month, week and day from \"dt\" column so that i can use them to fill null values\n",
    "    df['year'] = df['dt'].dt.year\n",
    "    df['month'] = df['dt'].dt.month\n",
    "    df['week'] = df['dt'].dt.week\n",
    "    df['day'] = df['dt'].dt.day\n",
    "\n",
    "    df['dt'] = df['dt'].dt.strftime('%Y-%m-%d')\n",
    "    df['dt'] =pd.to_datetime(df['dt'], format=\"%Y-%m-%d\")\n",
    "    \n",
    "    # Fill the null values for 'AverageTemperature' column based on \"Country\" , \"City\" , \"month\" and \"week\" columns\n",
    "    mapping1 = df.dropna().drop_duplicates().groupby([\"Country\",\"City\",\"month\",\"week\"])['AverageTemperature'].mean().to_dict()\n",
    "    df.loc[df[\"AverageTemperature\"].isna(), \"AverageTemperature\"] = df.loc[df[\"AverageTemperature\"].isna(), [\"Country\",\"City\",\"month\",\"week\"]].apply(lambda x : mapping1[(x[0],x[1],x[2],x[3])],axis=1)\n",
    "    \n",
    "    # Fill the null values for 'AverageTemperatureUncertainty' column based on \"Country\" , \"City\" , \"month\" and \"week\" columns\n",
    "    mapping2 = df.dropna().drop_duplicates().groupby([\"Country\",\"City\",\"month\",\"week\"])['AverageTemperatureUncertainty'].mean().to_dict()\n",
    "    df.loc[df[\"AverageTemperatureUncertainty\"].isna(), \"AverageTemperatureUncertainty\"] = df.loc[df[\"AverageTemperatureUncertainty\"].isna(), [\"Country\",\"City\",\"month\",\"week\"]].apply(lambda x : mapping2[(x[0],x[1],x[2],x[3])],axis=1)\n",
    "    \n",
    "    # Filter by year larger than 2000 since the dataset size is too large\n",
    "    df=df[df.year>2000]\n",
    "    \n",
    "    #Create table using apache spark and fill it with the cleaned dataset\n",
    "    schema_GlobalLandTemperaturesByCity = StructType([StructField(\"dt\", DateType() , True)\\\n",
    "                                                      ,StructField(\"AverageTemperature\", FloatType(), True)\\\n",
    "                                                      ,StructField(\"AverageTemperatureUncertainty\", FloatType(), True)\\\n",
    "                                                      ,StructField(\"City\", StringType(), True)\\\n",
    "                                                      ,StructField(\"Country\", StringType(), True)\\\n",
    "                                                      ,StructField(\"Latitude\", StringType(), True)\\\n",
    "                                                      ,StructField(\"Longitude\", StringType(), True)\\\n",
    "                                                      ,StructField(\"year\", IntegerType(), True)\\\n",
    "                                                      ,StructField(\"month\", IntegerType(), True)\\\n",
    "                                                      ,StructField(\"week\", IntegerType(), True)\\\n",
    "                                                      ,StructField(\"day\", IntegerType(), True)])\n",
    "\n",
    "    spark_GlobalLandTemperaturesByCity = spark.createDataFrame(df, schema=schema_GlobalLandTemperaturesByCity)\n",
    "    \n",
    "    # Get the average of AverageTemperature and AverageTemperatureUncertainty based on the country\n",
    "    df_GlobalLandTemperaturesByCity = spark_GlobalLandTemperaturesByCity.groupBy(col(\"Country\").alias(\"Country\"))\\\n",
    "    .agg(mean('AverageTemperature').alias(\"AverageTemperature\"),\\\n",
    "         mean(\"AverageTemperatureUncertainty\").alias(\"AverageTemperatureUncertainty\"))\\\n",
    "    .select([\"Country\", \"AverageTemperature\", \"AverageTemperatureUncertainty\"])\n",
    "    \n",
    "    # Write the table with parquet format\n",
    "    df_GlobalLandTemperaturesByCity.write.mode('overwrite').parquet(output_data+'GlobalLandTemperaturesByCity/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "GlobalLandTemperaturesByCity_fun(spark, output_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### demographics_df dimension table\n",
    "0. After exploring the dataset, there's no need to drop any column ,but there many steps to fill some null values and I included them within the function \n",
    "1. Read the us-cities-demographics dataset with pandas\n",
    "2. Fill the null values for 'Male Population' column based on \"State Code\" and  \"Race\" columns\n",
    "3. Fill the null values for 'Female Population' column by subtracting 'Male Population' column from 'Total Population' column\n",
    "4. Fill the null values for 'Foreign-born' column based on \"Race\" column\n",
    "5. Fill the null values for 'Average Household Size' column based on \"Race\" column\n",
    "6. Fill the null values for 'Number of Veterans' column based on \"Race\" column\n",
    "7. Create schema_demographics_df table using apache spark and fill it with the cleaned demographics_df dataset\n",
    "8. Select the columns to make changes on columns names with appropriate datatype\n",
    "9. Get the mean of Median_Age and Average_Household_Size and sum of Male_Population and Female_Population and Total_Population and Number_of_Veterans and Foreign_born based on the States\n",
    "10. Write the table with parquet format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demographics_df_fun(spark,output_data):\n",
    "    # Read the us-cities-demographics dataset with pandas\n",
    "    us_cities_demographics = 'us-cities-demographics.csv'\n",
    "    demographics_df = pd.read_csv(us_cities_demographics, header=0, sep=';')\n",
    "\n",
    "    # Fill the null values for 'Male Population' column based on \"State Code\" and \"Race\" columns\n",
    "\n",
    "    mapping1 = demographics_df.dropna().drop_duplicates().groupby([\"State Code\",\"Race\"])['Male Population'].mean().to_dict()\n",
    "    demographics_df.loc[demographics_df[\"Male Population\"].isna(), \"Male Population\"] = demographics_df.loc[demographics_df[\"Male Population\"].isna(), [\"State Code\",\"Race\"]].apply(lambda x : mapping1[(x[0],x[1])],axis=1)\n",
    "    \n",
    "    # Fill the null values for 'Female Population' column by subtracting 'Male Population' column from 'Total Population' column\n",
    "    demographics_df.loc[demographics_df[\"Female Population\"].isna(), \"Female Population\"] = demographics_df[\"Total Population\"] - demographics_df[\"Male Population\"]\n",
    "    # Fill the null values for 'Foreign-born' column based on \"Race\" column\n",
    "    mapping3 = demographics_df.dropna().drop_duplicates().groupby(\"Race\")['Foreign-born'].mean().to_dict()\n",
    "    demographics_df.loc[demographics_df[\"Foreign-born\"].isna(), \"Foreign-born\"] = demographics_df.loc[demographics_df[\"Foreign-born\"].isna(), [\"Race\"]].apply(lambda x : mapping3[(x[0])],axis=1)\n",
    "    # Fill the null values for 'Average Household Size' column based on \"Race\" column\n",
    "    mapping4 = demographics_df.dropna().drop_duplicates().groupby(\"Race\")['Average Household Size'].mean().to_dict()\n",
    "    demographics_df.loc[demographics_df[\"Average Household Size\"].isna(), \"Average Household Size\"] = demographics_df.loc[demographics_df[\"Average Household Size\"].isna(), [\"Race\"]].apply(lambda x : mapping4[(x[0])],axis=1)\n",
    "    \n",
    "    # Fill the null values for 'Number of Veterans' column based on \"Race\" column\n",
    "    mapping5 = demographics_df.dropna().drop_duplicates().groupby(\"Race\")['Number of Veterans'].mean().to_dict()\n",
    "    demographics_df.loc[demographics_df[\"Number of Veterans\"].isna(), \"Number of Veterans\"] = demographics_df.loc[demographics_df[\"Number of Veterans\"].isna(), [\"Race\"]].apply(lambda x : mapping5[(x[0])],axis=1)\n",
    "    # Create schema_demographics_df table using apache spark and fill it with the cleaned demographics_df dataset\n",
    "    schema_demographics_df = StructType([StructField(\"City\",StringType() , True)\\\n",
    "                                         ,StructField(\"State\", StringType(), True)\\\n",
    "                                         ,StructField(\"Median Age\", FloatType(), True)\\\n",
    "                                         ,StructField(\"Male Population\", FloatType(), True)\\\n",
    "                                         ,StructField(\"Female Population\", FloatType(), True)\\\n",
    "                                         ,StructField(\"Total Population\", IntegerType(), True)\\\n",
    "                                         ,StructField(\"Number of Veterans\", FloatType(), True)\\\n",
    "                                         ,StructField(\"Foreign-born\", FloatType(), True)\\\n",
    "                                         ,StructField(\"Average Household Size\", FloatType(), True)\\\n",
    "                                         ,StructField(\"State Code\", StringType(), True)\\\n",
    "                                         ,StructField(\"Race\", StringType(), True)\\\n",
    "                                         ,StructField(\"Count\", IntegerType(), True)])\n",
    "    # Select the columns to make changes on columns names with appropriate datatype\n",
    "    spark_demographics_df = spark.createDataFrame(demographics_df, schema=schema_demographics_df)\n",
    "    spark_demographics_df = spark_demographics_df.select(\"City\",\"State\",col(\"Median Age\").alias(\"Median_Age\"),col(\"Male Population\").cast('int').alias(\"Male_Population\"),\n",
    "                                                    col(\"Female Population\").cast('int').alias(\"Female_Population\"),col(\"Total Population\").alias(\"Total_Population\"),\n",
    "                                                    col(\"Number of Veterans\").cast('int').alias(\"Number_of_Veterans\"),col(\"Foreign-born\").cast('int').alias(\"Foreign_born\")\n",
    "                                                    ,col(\"Average Household Size\").alias(\"Average_Household_Size\"),col(\"State Code\").alias(\"State_Code\"),\"Race\",\"Count\")\n",
    "    # Get the mean of Median_Age and Average_Household_Size and sum of Male_Population and Female_Population and Total_Population and Number_of_Veterans and Foreign_born based on the States\n",
    "    spark_demographics_df = spark_demographics_df.groupBy(col(\"State_Code\").alias(\"State_Code\"),col(\"State\").alias(\"State\")).agg(\n",
    "        round(mean('Median_Age'),2).alias(\"Median_Age\"),\n",
    "        sum(\"Male_Population\").alias(\"Male_Population\"),\n",
    "        sum(\"Female_Population\").alias(\"Female_Population\"),\n",
    "        sum(\"Total_Population\").alias(\"Total_Population\"),\n",
    "        sum(\"Number_of_Veterans\").alias(\"Number_of_Veterans\"),\n",
    "        sum(\"Foreign_born\").alias(\"Foreign_born\"),\n",
    "        round(mean(\"Average_Household_Size\"),2).alias(\"Average_Household_Size\")).select([\"State\", \"state_code\", \"Median_Age\", \"Male_Population\",\"Female_Population\",\\\n",
    "         \"Total_Population\",\"Number_of_Veterans\",\"Foreign_born\",\"Average_Household_Size\"])\n",
    "    # Write the table with parquet format\n",
    "    spark_demographics_df.write.mode('overwrite').parquet(output_data+'demographics_df/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics_df_fun(spark, output_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I94Port dimension table\n",
    "1. Read I94_SAS_Labels_Descriptions file in text format as a wholetext\n",
    "2. Search for a specific section using udf in I94_SAS_Labels_Descriptions file\n",
    "3. Flatten the content in this section based on Newline and Carriage return\n",
    "4. Derive a new column from the flatten column and filter data by matching it with regular expressions \n",
    "5. Derive a new columns from the previous derived column to specify what the data we want to extract accurately\n",
    "6. Perform some cleaning steps such as updating some values and change the datatype for columns\n",
    "7. Write the extracted tables in parquet format.\n",
    "\n",
    "**The previous steps will be applied to extract five tables(I94CitRes, I94Port, I94Addr, I94Mode and I94Visa) and the I94Port table is the only table will be used as a dimension and the rest of tables will be used within the fact table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def i94_SAS_label_df_fun(spark, output_data):\n",
    "    \n",
    "    TextFile = 'I94_SAS_Labels_Descriptions.SAS'\n",
    "    df_label = spark.read.text(TextFile, wholetext=True)\n",
    "    \n",
    "    @udf\n",
    "    def matching(TextFile, TextPattern): \n",
    "        return re.search(TextPattern, TextFile).group(0)\n",
    "    # I94CIT & I94RES\n",
    "    df_I94CitRes_1 = df_label.withColumn('I94CitRes_1', matching(\"value\", lit(\"(\\/\\* I94CIT & I94RES[^;]+)\"))).select(\"I94CitRes_1\")\n",
    "    df_I94CitRes_2 = df_I94CitRes_1.withColumn('I94CitRes_2', explode(split(\"I94CitRes_1\", \"[\\r\\n]+\"))).select('I94CitRes_2')\n",
    "    df_I94CitRes_3 = df_I94CitRes_2.filter(df_I94CitRes_2['I94CitRes_2'].rlike(\"([0-9]+ *\\= *[0-9A-Za-z \\:\\',\\-()\\/\\.#&]+)\"))\\\n",
    "    .withColumn('country_code', regexp_extract(df_I94CitRes_2['I94CitRes_2'], \"[0-9]+\", 0))\\\n",
    "    .withColumn('country_code',col('country_code').cast(IntegerType()))\\\n",
    "    .withColumn('country_name', regexp_extract(df_I94CitRes_2['I94CitRes_2'], \"(?<=')([0-9A-Za-z \\:\\',\\-()\\/\\.#&]+)(?=')\", 0))\\\n",
    "    .withColumn('country_name',initcap(col('country_name')))\\\n",
    "    .withColumn('country_name',when(col('country_name') == 'Mexico Air Sea, And Not Reported (i-94, No Land Arrivals)','Mexico')\\\n",
    "                .otherwise(col('country_name'))).drop(\"I94CitRes_2\")\n",
    "    df_I94CitRes_3.write.mode('overwrite').parquet(output_data+'i94_SAS_label/I94CitRes/')\n",
    "    \n",
    "    # I94PORT\n",
    "    df_I94Port1 = df_label.withColumn('I94Port1', matching(\"value\", lit(\"(\\/\\* I94PORT[^;]+)\"))).select(\"I94Port1\")\n",
    "    df_I94Port2 = df_I94Port1.withColumn('I94Port_2', explode(split(\"I94Port1\", \"[\\r\\n]+\"))).select('I94Port_2')\n",
    "    df_I94Port3 = df_I94Port2.filter(df_I94Port2['I94Port_2'].rlike(\"([0-9A-Z.' ]+\\t*\\=\\t*[0-9A-Za-z \\',\\-()\\/\\.#&]*)\"))\\\n",
    "    .withColumn('portCode', regexp_extract(df_I94Port2['I94Port_2'], \"(?<=')[0-9A-Z. ]+(?=')\", 0))\\\n",
    "    .withColumn('cityName_stateCode', regexp_extract(col('I94Port_2'), \"(?<=\\t')([0-9A-Za-z ,\\-()\\/\\.#&]+)(?=')\", 0))\\\n",
    "    .withColumn('cityName', split(col('cityName_stateCode'), ',').getItem(0))\\\n",
    "    .withColumn('stateCode', split(col('cityName_stateCode'), ',').getItem(1))\\\n",
    "    .withColumn('stateCode', regexp_replace(col('stateCode'), '\\s*', ''))\\\n",
    "    .withColumn('cityName',initcap(col('cityName')))\\\n",
    "    .withColumn('stateCode', when(col('stateCode') == 'CA(BPS)','CA')\\\n",
    "                .when(col('stateCode') == 'AR(BPS)','AR')\\\n",
    "                .when(col('stateCode') == 'HWY.STATION','CA')\\\n",
    "                .when(col('stateCode') == 'CO#ARPT','CO')\\\n",
    "                .when(col('stateCode') == 'FL#ARPT','FL')\\\n",
    "                .when(col(\"stateCode\").isNull(), \"AZ\")\\\n",
    "                .otherwise(col('stateCode'))).drop('I94Port_2')\n",
    "    df_I94Port3=df_I94Port3.withColumn('stateCode',when((df_I94Port3.portCode == \"WAS\")&(df_I94Port3.stateCode == 'AZ') , \"DC\")\\\n",
    "                                       .otherwise(col('stateCode')))\n",
    "    df_I94Port3=df_I94Port3.withColumn('cityName', when(df_I94Port3.portCode == 'MAP','Mariposa').otherwise(col('cityName')))\n",
    "    df_I94Port3.write.mode('overwrite').parquet(output_data+'i94_SAS_label/I94Port/')\n",
    "    \n",
    "    # I94ADDR\n",
    "    df_I94Addr_1 = df_label.withColumn('I94Addr_1', matching(\"value\", lit(\"(\\/\\* I94ADDR[^;]+)\"))).select(\"I94Addr_1\")\n",
    "    df_I94Addr_2 = df_I94Addr_1.withColumn('I94Addr_2', explode(split(\"I94Addr_1\", \"[\\r\\n]+\"))).select('I94Addr_2')\n",
    "    df_I94Addr_3 = df_I94Addr_2.filter(df_I94Addr_2['I94Addr_2'].rlike(\"(\\t*[0-9A-Z.' ]+\\=\\t*[0-9A-Za-z \\',\\-()\\/\\.#&]*)\"))\\\n",
    "    .withColumn('stateCode', regexp_extract(df_I94Addr_2['I94Addr_2'], \"(?<=\\t')[0-9A-Z. ]+(?=')\", 0))\\\n",
    "    .withColumn('stateName', regexp_extract(df_I94Addr_2['I94Addr_2'], \"(?<=\\=')([0-9A-Za-z ,\\-()\\/\\.#&]+)(?=')\", 0))\\\n",
    "    .withColumn('stateName',initcap(col('stateName'))).drop(\"I94Addr_2\")\n",
    "    df_I94Addr_3.write.mode('overwrite').parquet(output_data+'i94_SAS_label/I94Addr/')\n",
    "    \n",
    "    # I94MODE\n",
    "    df_I94Mode_1 = df_label.withColumn('I94Mode_1', matching(\"value\", lit(\"(\\/\\* I94MODE[^;]+)\"))).select(\"I94Mode_1\")\n",
    "    df_I94Mode_2 = df_I94Mode_1.withColumn('I94Mode_2', explode(split(\"I94Mode_1\", \"[\\r\\n]+\"))).select('I94Mode_2')\n",
    "    df_I94Mode_3 = df_I94Mode_2.filter(df_I94Mode_2['I94Mode_2'].rlike(\"(\\t*[0-9]+ *\\= *[0-9A-Za-z \\',\\-()\\/\\.#&]*)\"))\\\n",
    "    .withColumn('travelModeCode', regexp_extract(df_I94Mode_2['I94Mode_2'], \"(?<=\\t)[0-9]+(?= )\", 0))\\\n",
    "    .withColumn('travelModeCode',col('travelModeCode').cast(IntegerType()))\\\n",
    "    .withColumn('travelModeName', regexp_extract(df_I94Mode_2['I94Mode_2'], \"(?<=\\= ')([A-Za-z ,\\-()\\/\\.#&]+)(?=')\", 0))\\\n",
    "    .drop(\"I94Mode_2\")\n",
    "    df_I94Mode_3.write.mode('overwrite').parquet(output_data+'i94_SAS_label/I94Mode/')\n",
    "    \n",
    "    # I94Visa\n",
    "    df_I94Visa_1 = df_label.withColumn('I94Visa_1', matching(\"value\", lit(\"(\\/\\* I94VISA[^;]+)\"))).select(\"I94Visa_1\")\n",
    "    df_I94Visa_2 = df_I94Visa_1.withColumn('I94Visa_2', explode(split(\"I94Visa_1\", \"[\\r\\n]+\"))).select('I94Visa_2')\n",
    "    df_I94Visa_3 = df_I94Visa_2.filter(df_I94Visa_2['I94Visa_2'].rlike(\"(\\s*[0-9]+ *\\= *[A-Za-z]*)\"))\\\n",
    "    .withColumn('VisaCategoryCode', regexp_extract(df_I94Visa_2['I94Visa_2'], \"[0-9]+\", 0))\\\n",
    "    .withColumn('VisaCategoryCode',col('VisaCategoryCode').cast(IntegerType()))\\\n",
    "    .withColumn('VisaCategoryName', regexp_extract(df_I94Visa_2['I94Visa_2'], \"[A-Za-z]+\", 0)).drop(\"I94Visa_2\")\n",
    "    df_I94Visa_3.write.mode('overwrite').parquet(output_data+'i94_SAS_label/I94Visa/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "i94_SAS_label_df_fun(spark, output_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ArrivalDate dimension table\n",
    "1. Read sas_data file\n",
    "2. Create function to get the date by adding the number of days between the chosen date and the reference date (01-01-1960) and use UDF to apply it in pyspark\n",
    "3. From this Date we extract columns such as  \"Year\", \"Month\", \"Week\", \"WeekDay\" and \"Day\"\n",
    "4. Write in parquet format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ArrivalDate_fun(spark, output_data):\n",
    "    #  Read sas_data file\n",
    "    #df_spark = spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')\n",
    "    df_spark=spark.read.parquet(\"sas_data\")\n",
    "    # Create function to get the date by adding the number of days between the chosen date and the reference date (01-01-1960) and use UDF to apply it in pyspark\n",
    "\n",
    "    def convert_to_dt(i):\n",
    "        try:\n",
    "            s = datetime(1960,1,1)\n",
    "            d = timedelta(days=int(i))\n",
    "            return s + d\n",
    "        except:\n",
    "            ex = datetime(1960,1,1)\n",
    "            return ex\n",
    "        \n",
    "    arrdate_datetime_udf = udf(lambda i: convert_to_dt(i), DateType())\n",
    "    \n",
    "    # From this Date we extract columns such as  \"Year\", \"Month\", \"Week\", \"WeekDay\" and \"Day\"\n",
    "    arrdate_df = df_spark.select([\"arrdate\"])\\\n",
    "    .withColumn(\"ArrivalDate\", arrdate_datetime_udf(\"arrdate\"))\\\n",
    "    .withColumn('Year', year('ArrivalDate'))\\\n",
    "    .withColumn('Month', month('ArrivalDate'))\\\n",
    "    .withColumn('Week', weekofyear('ArrivalDate'))\\\n",
    "    .withColumn('WeekDay', dayofweek('ArrivalDate'))\\\n",
    "    .withColumn('Day', dayofmonth('ArrivalDate'))\\\n",
    "    .select([\"arrdate\", \"ArrivalDate\", \"Year\", \"Month\", \"Week\", \"WeekDay\", \"Day\"])\\\n",
    "    .dropDuplicates([\"arrdate\"])\n",
    "    \n",
    "    # Write in parquet format   \n",
    "    arrdate_df.write.mode('overwrite').parquet(output_data+'ArrivalDate/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "ArrivalDate_fun(spark, output_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fact_i94 fact table\n",
    "1. Read sas_data file\n",
    "2. Get the percentage of null values for each column \n",
    "3. Drop column with 80% of null values or more\n",
    "4. Convert datatype of dtadfile and dtaddto columns to datetime format\n",
    "5. Create function to get the date by adding the number of days between the chosen date and the reference date (01-01-1960) and use UDF to apply it in pyspark and converted to datetime format\n",
    "6. Read the extracted tables I94Visa, I94Mode, I94Addr and I94CitRes from sas_labels and perform joins with i94 dataset\n",
    "7. Select the columns i choose to be within the fact table which includes the foreign keys for all dimensions tables and another columns with adjusted datatype\n",
    "8. Write fact_i94 tablein parquet format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def i94_df_fun(spark,output_data):\n",
    "    # Read sas_data file\n",
    "    df_spark = spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')\n",
    "    df_spark=spark.read.parquet(\"sas_data\")\n",
    "    \n",
    "    #Get the percentage of null values for each column\n",
    "    missing_percentage_df = df_spark.select([(count(when(isnan(c) | col(c).isNull(), c))*100/count(lit(1))).alias(c) for c in df_spark.columns])\n",
    "    missing_percentage_df = missing_percentage_df.collect()[0].asDict()\n",
    "    \n",
    "    # Drop column with 80% of null values or more\n",
    "    drop_columns = [k for k, v in missing_percentage_df.items() if v > 80]\n",
    "    i94_df = df_spark.drop(*drop_columns)\n",
    "    \n",
    "    # Convert datatype of dtadfile and dtaddto columns to datetime format\n",
    "    i94_df = i94_df.withColumn('dtadfile', to_date(col('dtadfile'), format='yyyyMMdd'))\\\n",
    "    .withColumn('dtaddto', to_date(col('dtaddto'), format='MMddyyyy'))\n",
    "    \n",
    "    # Create function to get the date by adding the number of days between the chosen date and the reference date (01-01-1960) and use UDF to apply it in pyspark and converted to datetime format\n",
    "\n",
    "    def convert_to_dt(i):\n",
    "        try:\n",
    "            s = datetime(1960,1,1)\n",
    "            d = timedelta(days=int(i))\n",
    "            return s + d\n",
    "        except:\n",
    "            ex = datetime(1960,1,1)\n",
    "            return ex\n",
    "    \n",
    "    depdate_datetime_udf = udf(lambda i: convert_to_dt(i), DateType())\n",
    "    i94_df = i94_df.withColumn('depdate', to_date(depdate_datetime_udf(col('depdate'))))\n",
    "    \n",
    "    # Read the extracted tables I94Visa, I94Mode, I94Addr and I94CitRes from sas_labels and perform joins with i94 dataset\n",
    "    df_I94Visa=spark.read.parquet(\"abdullahoutput/i94_SAS_label/I94Visa\")\n",
    "    df_I94Mode=spark.read.parquet(\"abdullahoutput/i94_SAS_label/I94Mode\")\n",
    "    df_I94Addr=spark.read.parquet(\"abdullahoutput/i94_SAS_label/I94Addr\")\n",
    "    df_I94CitRes=spark.read.parquet(\"abdullahoutput/i94_SAS_label/I94CitRes\")\n",
    "    \n",
    "    i94_full_df = i94_df.join(df_I94CitRes,[i94_df.i94res==df_I94CitRes.country_code])\\\n",
    "    .withColumnRenamed(\"country_code\",\"country_code_res\").withColumnRenamed(\"country_name\",\"country_name_res\")\n",
    "    \n",
    "    i94_full_df1 = i94_full_df.join(df_I94CitRes,[i94_full_df.i94cit==df_I94CitRes.country_code])\\\n",
    "    .withColumnRenamed(\"country_code\",\"country_code_cit\").withColumnRenamed(\"country_name\",\"country_name_cit\")\n",
    "\n",
    "    i94_full_df2 = i94_full_df1.join(df_I94Mode,[i94_full_df1.i94mode==df_I94Mode.travelModeCode])\n",
    "    i94_full_df3 = i94_full_df2.join(df_I94Addr,[i94_full_df2.i94addr==df_I94Addr.stateCode])\n",
    "    i94_full_df4 = i94_full_df3.join(df_I94Visa,[i94_full_df3.i94visa==df_I94Visa.VisaCategoryCode])\n",
    "    \n",
    "    # Select the columns i choose to be within the fact table which includes the foreign keys for all dimensions tables and another columns with adjusted datatype\n",
    "    i94_full_df5 = i94_full_df4.select(col(\"cicid\").cast('int'),col(\"i94yr\").cast('int'),col(\"i94mon\").cast('int'),\n",
    "                                       \"country_code_cit\",\"country_name_cit\",\n",
    "                                       \"country_code_res\",\"country_name_res\",\"travelModeCode\",\"travelModeName\",\"stateCode\",\n",
    "                                       \"stateName\",\"fltno\",col(\"admnum\").cast('int'),\"airline\",\"gender\",\n",
    "                                       \"dtadfile\",\"dtaddto\",col(\"biryear\").cast('int'),\"entdepa\",\"entdepd\",\"matflag\",\n",
    "                                       col(\"i94bir\").cast('int'),\"arrdate\",\"depdate\",\"i94port\",\"VisaCategoryCode\",\"VisaCategoryName\",\n",
    "                                       \"visatype\",\"visapost\")\n",
    "    # Write fact_i94 tablein parquet format\n",
    "    i94_full_df5.write.mode('overwrite').parquet(output_data+'fact_i94/')\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "i94_df_fun(spark,output_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "* Data quality checks in two steps for each table:\n",
    "    1. data_quality_checks function is about comparing between the number of rows after the pipeline process and the real value or expected value for table. if they are identical ,then the check will pass.\n",
    "    2. data_quality_checks function is about primary key duplication of the table and checking if its value is zero or not. if its value is zero, then the check will pass.\n",
    "* Finally, if any table doesn't pass the quality check, then the whole data_quality_checks will fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_quality_checks():\n",
    "    df_fact_i94=spark.read.parquet(\"abdullahoutput/fact_i94\")\n",
    "    df_ArrivalDate=spark.read.parquet(\"abdullahoutput/ArrivalDate\")\n",
    "    df_demographics_df=spark.read.parquet(\"abdullahoutput/demographics_df\")\n",
    "    df_GlobalLandTemperaturesByCity=spark.read.parquet(\"abdullahoutput/GlobalLandTemperaturesByCity\")\n",
    "    df_I94Port=spark.read.parquet(\"abdullahoutput/i94_SAS_label/I94Port\")\n",
    "    \n",
    "    data_quality_checks=[{'check_count_of_Dataset': df_fact_i94.count(), 'real_count_of_Dataset': 2559296,\n",
    "                          'check_count_duplicate_of_unique_key': df_fact_i94.groupBy(\"cicid\").count().where(\"count > 1\").count(), 'real_count_duplicate_of_unique_key': 0,\"table\":\"df_fact_i94\"},\n",
    "                         {'check_count_of_Dataset': df_ArrivalDate.count(), 'real_count_of_Dataset': 30,\n",
    "                          'check_count_duplicate_of_unique_key': df_ArrivalDate.groupBy(\"arrdate\").count().where(\"count > 1\").count(), 'real_count_duplicate_of_unique_key': 0,\"table\":\"df_ArrivalDate\"},\n",
    "                         {'check_count_of_Dataset': df_demographics_df.count(), 'real_count_of_Dataset': 49,\n",
    "                          'check_count_duplicate_of_unique_key': df_demographics_df.groupBy(\"State\").count().where(\"count > 1\").count(), 'real_count_duplicate_of_unique_key': 0,\"table\":\"df_demographics_df\"},\n",
    "                         {'check_count_of_Dataset': df_GlobalLandTemperaturesByCity.count(), 'real_count_of_Dataset': 159,\n",
    "                          'check_count_duplicate_of_unique_key': df_GlobalLandTemperaturesByCity.groupBy(\"Country\").count().where(\"count > 1\").count(), 'real_count_duplicate_of_unique_key': 0,\"table\":\"df_GlobalLandTemperaturesByCity\"},\n",
    "                         {'check_count_of_Dataset': df_I94Port.count(), 'real_count_of_Dataset': 660,\n",
    "                          'check_count_duplicate_of_unique_key': df_I94Port.groupBy(\"portCode\").count().where(\"count > 1\").count(), 'real_count_duplicate_of_unique_key': 0,\"table\":\"df_I94Port\"}]\n",
    "    \n",
    "    \n",
    "    count_error = 0\n",
    "    for check in data_quality_checks:\n",
    "        check_dataset_count = check.get('check_count_of_Dataset')\n",
    "        real__dataset_count = check.get('real_count_of_Dataset')\n",
    "        check_uniquekey_count = check.get('check_count_duplicate_of_unique_key')\n",
    "        real_uniquekey_count = check.get('real_count_duplicate_of_unique_key')\n",
    "        table_name = check.get('table')\n",
    "         \n",
    "        if ((check_dataset_count== real__dataset_count) and (check_uniquekey_count== real_uniquekey_count)):\n",
    "            print(f\"Data quality check pass at {table_name} table\")\n",
    "            \n",
    "        else:\n",
    "            count_error += 1\n",
    "            print(f\"Data quality check fails at {table_name} table\")\n",
    "    if count_error > 0:\n",
    "        print('Data quality checks failed')\n",
    "    else:\n",
    "        print('Data quality checks passed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data quality check pass at df_fact_i94 table\n",
      "Data quality check pass at df_ArrivalDate table\n",
      "Data quality check pass at df_demographics_df table\n",
      "Data quality check pass at df_GlobalLandTemperaturesByCity table\n",
      "Data quality check pass at df_I94Port table\n",
      "Data quality checks passed\n"
     ]
    }
   ],
   "source": [
    "# Perform quality checks here\n",
    "data_quality_checks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fact Table: this is the fact table from the cleaned I94 dataset\n",
    "\n",
    "| Feature      | Description |\n",
    "| ----------- | ----------- |\n",
    "| cicid      | Unique ID       |\n",
    "|i94yr| year        |\n",
    "|i94mon| month|\n",
    "|country_code_cit| 3 digit code for immigrant country of birth|\n",
    "|country_name_cit| Name for immigrant country of birth|\n",
    "|country_code_res| 3 digit code for immigrant country of residence|\n",
    "|country_name_res| Name for immigrant country of residence|\n",
    "|travelModeCode| Mode of transportation (1 = Air; 2 = Sea; 3 = Land; 9 = Not reported)|\n",
    "|travelModeName| Mode name of transportation|\n",
    "|stateCode| USA State code of arrival|\n",
    "|stateName| USA State name of arrival|\n",
    "|fltno| Flight number of Airline used to arrive in U.S.|\n",
    "|admnum| Admission Number|\n",
    "|airline| Airline used to arrive in U.S|\n",
    "|gender| Non-immigrant sex|\n",
    "|dtadfile|Character Date Field - Date added to I-94 Files|\n",
    "|dtaddto|Character Date Field - Date to which admitted to U.S. (allowed to stay until)|\n",
    "|biryear|4 digit year of birth|\n",
    "|entdepa| Arrival Flag - admitted or paroled into the U.S.|\n",
    "|entdepd|Departure Flag - Departed, lost I-94 or is deceased|\n",
    "|matflag|Match flag - Match of arrival and departure records|\n",
    "|i94bir|Age of Respondent in Years|\n",
    "|arrdate|Arrival Date in the USA|\n",
    "|depdate|Departure Date from the USA|\n",
    "|i94port|Port of admission|\n",
    "|VisaCategoryCode| Visa codes collapsed into three categories|\n",
    "|VisaCategoryName| Visa name collapsed into three categories|\n",
    "|visatype|Class of admission legally admitting the non-immigrant to temporarily stay in U.S|\n",
    "|visapost|Department of State where Visa was issued|\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### demographics_df dimension table : this dimension table is created from the us_cities_demographics dataset. This dimension can join the fact table through the stateCode feature.\n",
    "\n",
    "| Feature      | Description |\n",
    "| ----------- | ----------- |\n",
    "|State | US State of the City|\n",
    "|Median Age | The median population age|\n",
    "|Male Population | Male population total|\n",
    "|Female Population | Female population total|\n",
    "|Total Population | Total population|\n",
    "|Number of Veterans | Number of veterans living in the city|\n",
    "|Foreign-born | Number of residents who were not born in the city|\n",
    "|Average Household Size | Average size of houses in the city|\n",
    "|State Code | Code of the state|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GlobalLandTemperaturesByCity dimension table: this dimension table is created from the GlobalLandTemperaturesByCity dataset. This dimension can join the fact table through the Country feature.\n",
    "\n",
    "| Feature      | Description |\n",
    "| ----------- | ----------- |\n",
    "|Country | Name of country|\n",
    "|AverageTemperature | Average temperature in celsius|\n",
    "|AverageTemperatureUncertainty | 95% confidence interval around average temperature|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I94Port dimension table: this dimension table is extracted from the i94 sas_label file. This dimension can join the fact table through the i94port feature.\n",
    "\n",
    "| Feature      | Description |\n",
    "| ----------- | ----------- |\n",
    "|portCode | Port of admission|\n",
    "|cityName_stateCode | The name of city and code of the state|\n",
    "|cityName |  The name of city|\n",
    "|stateCode|The code of the state|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ArrivalDate dimension table: this dimension table is extracted and created from the i94 dataset. This dimension can join the fact table through the i94port feature.\n",
    "\n",
    "| Feature      | Description |\n",
    "| ----------- | ----------- |\n",
    "|arrdate | Arrival Date in the USA|\n",
    "|ArrivalDate | Arrival Date in the USA in date time format|\n",
    "|Year |  Year|\n",
    "|Month|Month|\n",
    "|Week|Week of year|\n",
    "|WeekDay|Day of week|\n",
    "|Day|Day of month|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The process result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The fact and dimensions tables: \n",
    "df_fact_i94=spark.read.parquet(\"abdullahoutput/fact_i94\")\n",
    "df_ArrivalDate=spark.read.parquet(\"abdullahoutput/ArrivalDate\")\n",
    "df_demographics_df=spark.read.parquet(\"abdullahoutput/demographics_df\")\n",
    "df_GlobalLandTemperaturesByCity=spark.read.parquet(\"abdullahoutput/GlobalLandTemperaturesByCity\")\n",
    "df_I94Port=spark.read.parquet(\"abdullahoutput/i94_SAS_label/I94Port\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>country_code_cit</th>\n",
       "      <th>country_name_cit</th>\n",
       "      <th>country_code_res</th>\n",
       "      <th>country_name_res</th>\n",
       "      <th>travelModeCode</th>\n",
       "      <th>travelModeName</th>\n",
       "      <th>stateCode</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepd</th>\n",
       "      <th>matflag</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94port</th>\n",
       "      <th>VisaCategoryCode</th>\n",
       "      <th>VisaCategoryName</th>\n",
       "      <th>visatype</th>\n",
       "      <th>visapost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5748517</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>245</td>\n",
       "      <td>China, Prc</td>\n",
       "      <td>438</td>\n",
       "      <td>Australia</td>\n",
       "      <td>1</td>\n",
       "      <td>Air</td>\n",
       "      <td>CA</td>\n",
       "      <td>...</td>\n",
       "      <td>O</td>\n",
       "      <td>M</td>\n",
       "      <td>40</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1960-01-01</td>\n",
       "      <td>LOS</td>\n",
       "      <td>1</td>\n",
       "      <td>Business</td>\n",
       "      <td>B1</td>\n",
       "      <td>SYD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5748518</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>245</td>\n",
       "      <td>China, Prc</td>\n",
       "      <td>438</td>\n",
       "      <td>Australia</td>\n",
       "      <td>1</td>\n",
       "      <td>Air</td>\n",
       "      <td>NV</td>\n",
       "      <td>...</td>\n",
       "      <td>O</td>\n",
       "      <td>M</td>\n",
       "      <td>32</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1960-01-01</td>\n",
       "      <td>LOS</td>\n",
       "      <td>1</td>\n",
       "      <td>Business</td>\n",
       "      <td>B1</td>\n",
       "      <td>SYD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     cicid  i94yr  i94mon  country_code_cit country_name_cit  \\\n",
       "0  5748517   2016       4               245       China, Prc   \n",
       "1  5748518   2016       4               245       China, Prc   \n",
       "\n",
       "   country_code_res country_name_res  travelModeCode travelModeName stateCode  \\\n",
       "0               438        Australia               1            Air        CA   \n",
       "1               438        Australia               1            Air        NV   \n",
       "\n",
       "    ...    entdepd matflag  i94bir  arrdate     depdate i94port  \\\n",
       "0   ...          O       M      40  20574.0  1960-01-01     LOS   \n",
       "1   ...          O       M      32  20574.0  1960-01-01     LOS   \n",
       "\n",
       "  VisaCategoryCode  VisaCategoryName visatype visapost  \n",
       "0                1          Business       B1      SYD  \n",
       "1                1          Business       B1      SYD  \n",
       "\n",
       "[2 rows x 29 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fact_i94.limit(2).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2559296"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fact_i94.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arrdate</th>\n",
       "      <th>ArrivalDate</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Week</th>\n",
       "      <th>WeekDay</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20558.0</td>\n",
       "      <td>1960-01-01</td>\n",
       "      <td>1960</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20571.0</td>\n",
       "      <td>1960-01-01</td>\n",
       "      <td>1960</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   arrdate ArrivalDate  Year  Month  Week  WeekDay  Day\n",
       "0  20558.0  1960-01-01  1960      1    53        6    1\n",
       "1  20571.0  1960-01-01  1960      1    53        6    1"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ArrivalDate.limit(2).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ArrivalDate.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>state_code</th>\n",
       "      <th>Median_Age</th>\n",
       "      <th>Male_Population</th>\n",
       "      <th>Female_Population</th>\n",
       "      <th>Total_Population</th>\n",
       "      <th>Number_of_Veterans</th>\n",
       "      <th>Foreign_born</th>\n",
       "      <th>Average_Household_Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>DC</td>\n",
       "      <td>33.80</td>\n",
       "      <td>1598525</td>\n",
       "      <td>1762615</td>\n",
       "      <td>3361140</td>\n",
       "      <td>129815</td>\n",
       "      <td>475585</td>\n",
       "      <td>2.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>AR</td>\n",
       "      <td>32.74</td>\n",
       "      <td>1400724</td>\n",
       "      <td>1482165</td>\n",
       "      <td>2882889</td>\n",
       "      <td>154390</td>\n",
       "      <td>307753</td>\n",
       "      <td>2.53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  State state_code  Median_Age  Male_Population  \\\n",
       "0  District of Columbia         DC       33.80          1598525   \n",
       "1              Arkansas         AR       32.74          1400724   \n",
       "\n",
       "   Female_Population  Total_Population  Number_of_Veterans  Foreign_born  \\\n",
       "0            1762615           3361140              129815        475585   \n",
       "1            1482165           2882889              154390        307753   \n",
       "\n",
       "   Average_Household_Size  \n",
       "0                    2.24  \n",
       "1                    2.53  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demographics_df.limit(2).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demographics_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bosnia And Herzegovina</td>\n",
       "      <td>11.593267</td>\n",
       "      <td>0.428826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>10.110256</td>\n",
       "      <td>0.262104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Country  AverageTemperature  AverageTemperatureUncertainty\n",
       "0  Bosnia And Herzegovina           11.593267                       0.428826\n",
       "1          United Kingdom           10.110256                       0.262104"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_GlobalLandTemperaturesByCity.limit(2).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_GlobalLandTemperaturesByCity.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>portCode</th>\n",
       "      <th>cityName_stateCode</th>\n",
       "      <th>cityName</th>\n",
       "      <th>stateCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALC</td>\n",
       "      <td>ALCAN, AK</td>\n",
       "      <td>Alcan</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANC</td>\n",
       "      <td>ANCHORAGE, AK</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  portCode      cityName_stateCode   cityName stateCode\n",
       "0      ALC  ALCAN, AK                   Alcan        AK\n",
       "1      ANC  ANCHORAGE, AK           Anchorage        AK"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_I94Port.limit(2).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "660"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_I94Port.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to use the tables ?\n",
    "\n",
    "- Which State of US the people visit for pleasure and what is the mean age of the state people.\n",
    "\n",
    "\n",
    "- This model could be used to explore the temperature impact on the travelers and what kind of visa they get.\n",
    "\n",
    "\n",
    "- This model could be used to explore the correlation between the number of airports for each city and state and the size of travelers flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which State of US the male and female visit for pleasure and what is the mean age of the state people\n",
    "df_fact_i94=spark.read.parquet(\"abdullahoutput/fact_i94\")\n",
    "df_demographics_df=spark.read.parquet(\"abdullahoutput/demographics_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff=df_fact_i94.join(df_demographics_df,[df_fact_i94.stateCode==df_demographics_df.state_code])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff=dff.filter(dff.VisaCategoryName == \"Pleasure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfff=dff.select([\"State\",\"Median_Age\",\"Male_Population\",\"Female_Population\"]).dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+---------------+-----------------+\n",
      "|        State|Median_Age|Male_Population|Female_Population|\n",
      "+-------------+----------+---------------+-----------------+\n",
      "| South Dakota|     37.05|         613590|           611900|\n",
      "|       Alaska|      32.2|         764725|           728750|\n",
      "|         Iowa|     32.54|        1772066|          1831937|\n",
      "|     Virginia|     34.43|        5802370|          6015740|\n",
      "|      Alabama|     36.16|        2448200|          2715106|\n",
      "|    Tennessee|     34.31|        5124189|          5565976|\n",
      "|     Colorado|     35.82|        7273095|          7405250|\n",
      "|     New York|     35.57|       23422799|         25579256|\n",
      "|       Oregon|     36.13|        3537215|          3645330|\n",
      "|     Kentucky|     35.95|        2262415|          2386970|\n",
      "|Massachusetts|     35.55|        4841101|          5155944|\n",
      "|   Washington|     35.29|        6228025|          6272510|\n",
      "|     Arkansas|     32.74|        1400724|          1482165|\n",
      "| Pennsylvania|     33.95|        5514704|          5988097|\n",
      "|   California|     36.17|       61055672|         62388681|\n",
      "|New Hampshire|      37.8|         488855|           502135|\n",
      "|  Connecticut|      35.0|        2123435|          2231661|\n",
      "|     Maryland|     36.37|        3139755|          3420890|\n",
      "|    Wisconsin|     33.51|        3444015|          3621710|\n",
      "|    Minnesota|     35.58|        3478803|          3565362|\n",
      "+-------------+----------+---------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfff.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfff.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* The rationale for the choice of tools and technologies for the project.\n",
    "    - Apache Spark is the technology that used in this project since it can handle large amounts of data in parallel distributed fashion with high velocity\n",
    "* How often the data should be updated and why.\n",
    "    - The dataset should be updated monthly since the I94 dataset that i worked on is updated monthly \n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    "     - I would have scaled up the cluster that i work through by increasing the number of nodes in my cluster so that the performance becomes fast\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    "     - I use Apache Airflow to schedule and run data pipelines for daily execution at 7am.\n",
    " * The database needed to be accessed by 100+ people.\n",
    "     - We will use Amazon Redshift to perform the database analytics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
